{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa8b1fa",
   "metadata": {},
   "source": [
    "# Versions of the Timeseries Quantum Autoencoder\n",
    "*TS QAE in PennyLane with angle encoding of TS sliding windows*\n",
    "\n",
    "**Authors:**\n",
    "- Jacob Cybulski, Enquanted, Australia\n",
    "- Sebastian Zając, Warsaw School of Economics, Poland\n",
    "- Jakub Zwoniarski, Poland\n",
    "- Artur Strąg, Poland\n",
    "- Paweł Gora, Quantum AI Foundation, Poland\n",
    "  \n",
    "**Date:** Aug 2023 - Sept 2025\n",
    "\n",
    "**Aims:**\n",
    "> The goal of this series of notebooks is to build a Time Series Quantum Autoencoder,<br>\n",
    "> a circuit which can compress a quantum state of a time series onto a smaller amount of qubits,<br>\n",
    "> while retaining the information from the initial state.\n",
    "\n",
    "**Methods:** The QAE solution was inspired by the \"Qiskit Tutorial 12\"\n",
    "- Time series data was converted to a series of sliding windows.\n",
    "- Several approaches to TS data encoding were tested, i.e. unary, binary and anglular.\n",
    "- Angle encoding was eventually used, with values centered around H state, in the range of [0+m..1-m]\n",
    "- The model featuring an input and encoder blocks only (optional swap test) was subsequently trained.\n",
    "- For testing, and the circuit was initialised with an optimum set of parameters from training.\n",
    "- Each test sample was then encoded into the QAE circuit, which was executed using a state vector simulation.\n",
    "- State vectors of input and output data was then visualised and compared. \n",
    "\n",
    "**Sources:** \n",
    "1. Romero, Jonathan, Jonathan P. Olson, and Alan Aspuru-Guzik. 2017. “Quantum Autoencoders for Efficient Compression of Quantum Data.”<br/>\n",
    "   Quantum Science and Technology 2 (4): 045001.\n",
    "3. Bravo-Prieto, Carlos, \"Quantum autoencoders with enhanced data encoding.\" Machine Learning: Science and Technology, 2, May 2021\n",
    "4. Qiskit Tutorial, https://qiskit.org/ecosystem/machine-learning/tutorials/12_quantum_autoencoder.html. *Based on [1].*\n",
    "5. Eugenia Anello, Denoising Autoencoder in Pytorch on MNIST dataset, Dataseries (Medium), Jun 28, 2021.\n",
    "6. Eugenia Anello, <a href=\"https://github.com/eugeniaring/Medium-Articles/blob/main/Pytorch/denAE.ipynb\">GitHub</a>, Jun 28, 2021.\n",
    "7. Phillip Lippe, Tutorial 9: Deep Autoencoders, UvA Deep Learning Tutorials, Fall 2022.\n",
    "\n",
    "**Notes:**\n",
    "- Refer to the end of the notebook for the log of changes\n",
    "- Algorithm by Romera was tested\n",
    "- Results of the enhanced algorithm by Bravo-Prieto could not be reproduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ce40c7-6be0-491b-aa49-8c57d60f5d3a",
   "metadata": {},
   "source": [
    "## Initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b6ee277-2ea4-4716-b247-636973761a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1eb3c",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44364ae",
   "metadata": {},
   "source": [
    "1. A wikipedia page on Autoencoder: https://en.wikipedia.org/wiki/Autoencoder\n",
    "\n",
    "2. Romero, Jonathan, Jonathan P. Olson, and Alan Aspuru-Guzik. \"Quantum autoencoders for efficient compression of quantum data.\" Quantum Science and Technology 2.4 (2017): 045001.\n",
    "\n",
    "3. Swap Test Algorithm: https://en.wikipedia.org/wiki/Swap_test\n",
    "\n",
    "4. Bravo-Prieto, Carlos, \"Quantum autoencoders with enhanced data encoding.\" Machine Learning: Science and Technology, 2, May 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d44e07-b6b6-4741-89fe-28f801ba427e",
   "metadata": {},
   "source": [
    "## Versions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c00e9f-ebb2-4d58-a9b1-3bb246516858",
   "metadata": {},
   "source": [
    "**PennyLane full-QAE with Angle Encoding (Monolith)**\n",
    "- V5 Using QAE for noise reduction (moved from Qiskit and simplified)\n",
    "    - V5,11 (25-07-02) Implemented as an illustration of QAE working principles\n",
    "      - *Issue 01:* Slow training\n",
    "      - *Issue 02: ($\\checkmark$)* Training data for all iterations needs to be saved (costs, parameters, initial weights)\n",
    "      - **Issue 03:** Complex analysis (MSE, MAE, R2 for training and testing) and charting should move to a separate notebook\n",
    "      - **Issue 04:** *n_inst* instances of each model need to be created, trained, tested and stats analysed (say 10)\n",
    "      - *Issue 05:* Test that QAE is better than noise averaging\n",
    "      - **Issue 06:** Test how QAE compares with classical AE\n",
    "      - *Issue 07:* Different model architectures need to be tested (half and full QAEs in different configurations)\n",
    "      - *Issue 08:* For each QAE architecture training needs to be parametrised and possibly executed in batch on remote machines,\n",
    "        with all results saved for further analysis, possible hyperparameters to consider include:\n",
    "        - _**Data parameters to vary:**_ data type (Mackey-Glass/Sine/Beer), sample size, window size, sliding step, etc.\n",
    "        - _**Model parameters to vary:**_ encoding method (e.g. Ry / Rxyz), number of layers, size of latent/trash space,\n",
    "          numer of additional qubits, etc.\n",
    "        - _**Training parameters to vary:**_ optimizser (gradient/stochastic/quantum natural), optimiser parameters,\n",
    "          differentiation method (backprop/adjoint/parameter-shift), interface = (device specific/numpy/torch/jax),\n",
    "          data shuffling and frequency, loss/cost_(L1$\\rightarrow$MAE/L2$\\rightarrow$MSE/others), number of shots (None/more),\n",
    "          number of training epochs, number of model instances to train, etc.\n",
    "    - V5.12 (25-07-03) Larger model, wrap around improved training, better plots with stats\n",
    "      - **Fixed 02:** All training data is now saved in the log repository\n",
    "    - V5.12 (25-09-08) Implemented and run completed\n",
    "      - *Issue 09:* Tests seem to give a terrible performance (possibly incorrect model)\n",
    "    - V5.13 (25-09-10) Fixes and extensions\n",
    "      - **Fixed 01** Improved training speed\n",
    "      - **Fixed 05** Added comparison of noise elimination against noise level\n",
    "      - **Work 07** Half-QAE and Sidekick-QAE are in ../Artur and ../Jacob\n",
    "      - **Work 08** Parameterization in ../Jacob (some will move here)\n",
    "      - **Fixed 09** Fixed bad encoding\n",
    "      - Created two new more chaotic dataset (tau=17 and tau=30, len=200)\n",
    "      - Trained two models for each new dataset (best with noise=0.2)\n",
    "      - Updated and corrected Windows/ts_add_noise to allow normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f7441d-aa59-4726-af60-ca1787a69236",
   "metadata": {},
   "source": [
    "# Software in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b006922d-333f-47e2-a360-0163fc0a87e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch                     2.6.0+cu126\n",
      "torch-geometric           2.6.1\n",
      "torchaudio                2.6.0+cu126\n",
      "torcheval                 0.0.7\n",
      "torchsummary              1.5.1\n",
      "torchvision               0.21.0+cu126\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -E 'qiskit|torch'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
