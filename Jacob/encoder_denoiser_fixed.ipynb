{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860a3a39",
   "metadata": {},
   "source": [
    "# Fixed Encoder Denoiser (Adjoint-Compatible, Train Encoder Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d0be897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device ready. n_qubits= 4  latent= 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports & basic setup\n",
    "import os, json, math, random\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Configuration (matches your V9: 4 qubits, 2-latent)\n",
    "n_qubits = 4\n",
    "n_latent = 2\n",
    "signal_wires = [0, 1]   # <- where we want to reconstruct\n",
    "trash_wires  = [2, 3]\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "# Scaling helpers (keep differentiable with pnp)\n",
    "def scale_back(expvals, info):\n",
    "    return (expvals + 1.0) / 2.0 * (info['scale_high'] - info['scale_low']) + info['scale_low']\n",
    "\n",
    "def scale_to_angles(x):\n",
    "    # Expect inputs normalized to [0,1] already; map to [0, pi]\n",
    "    return x * np.pi\n",
    "\n",
    "print(\"Device ready. n_qubits=\", n_qubits, \" latent=\", n_latent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1ab68",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'qae_architectures/jacobs_examples/aintern/data/mackey_glass_n100/half_qae_v9_compression_success.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_folder:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate data folder under \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m DATA_PATH)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     14\u001b[0m     info \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Prefer the exact V9 success filename; fallback to first matching\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'qae_architectures/jacobs_examples/aintern/data/mackey_glass_n100/half_qae_v9_compression_success.json'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load decoder parameters from your data folder (same logic as your original NB)\n",
    "DATA_PATH = \"qae_architectures/jacobs_examples/aintern/data/mackey_glass_n100\"\n",
    "data_folder = \"half_qae_v9_compression_success.json\"\n",
    "# Probe for any folder containing the JSON\n",
    "if os.path.isdir(DATA_PATH):\n",
    "    for d in os.listdir(DATA_PATH):\n",
    "        if os.path.isdir(os.path.join(DATA_PATH, d)):\n",
    "            data_folder = d\n",
    "            break\n",
    "if not data_folder:\n",
    "    raise RuntimeError(\"Could not locate data folder under \" + DATA_PATH)\n",
    "/Users/jacobzwoniarski/Desktop/qae_architectures/jacobs_examples/aintern/data/mackey_glass_n100/half_qae_v9_compression_success.json\n",
    "with open(f\"{DATA_PATH}/{data_folder}\", \"r\") as f:\n",
    "    info = json.load(f)\n",
    "\n",
    "# Prefer the exact V9 success filename; fallback to first matching\n",
    "cand = [f for f in os.listdir(f\"{DATA_PATH}/{data_folder}\") if f.startswith(\"half_qae_v9_compression_success.json\")]\n",
    "if not cand:\n",
    "    cand = [f for f in os.listdir(f\"{DATA_PATH}/{data_folder}\") if f.endswith(\"half_qae_v9_compression_success.json\")]\n",
    "if not cand:\n",
    "    raise RuntimeError(\"Could not find half_qae_v9_compression_success.json in the data folder.\")\n",
    "\n",
    "with open(os.path.join(DATA_PATH, data_folder, cand[0]), \"r\") as f:\n",
    "    saved = json.load(f)\n",
    "\n",
    "trained_dec_params = pnp.array(saved[\"dec_params\"], requires_grad=False)\n",
    "print(\"Loaded decoder params:\", trained_dec_params.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e68f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Decoder template (exact V9 latent-only parameterization + light entanglement) ---\n",
    "def decoder_template(params):\n",
    "    n_layers = len(params) // (n_latent * 3)\n",
    "    # Parametrized single-qubit rotations on latent wires only\n",
    "    for layer in range(n_layers):\n",
    "        for i in range(n_latent):\n",
    "            idx = layer * n_latent * 3 + i * 3\n",
    "            qml.RX(params[idx], wires=i)\n",
    "            qml.RY(params[idx + 1], wires=i)\n",
    "            qml.RZ(params[idx + 2], wires=i)\n",
    "        # light entanglement between latent qubits\n",
    "        if layer < n_layers - 1:\n",
    "            qml.CNOT(wires=[0, 1])\n",
    "\n",
    "    # Trash wires have fixed, *non-trainable* initialization (as in your V9)\n",
    "    qml.RX(np.pi/3, wires=2);  qml.RY(np.pi/4, wires=2);  qml.RZ(np.pi/6, wires=2)\n",
    "    qml.RY(-np.pi/3, wires=3); qml.RX(np.pi/5, wires=3); qml.RZ(-np.pi/4, wires=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd539a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Encoder template as *parameterized adjoint* of the decoder architecture ---\n",
    "# Key idea: SAME gate skeleton as the decoder, but trained parameters are free (phi).\n",
    "# Using qml.adjoint on the decoder_template ensures architectural compatibility.\n",
    "def encoder_template(phi):\n",
    "    qml.adjoint(decoder_template)(phi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d10c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input embedding (your V9 used RY(angle) data embedding on all 4 qubits)\n",
    "def embed_input(x):\n",
    "    # x expected shape (..., n_qubits) in [0,1]; we only use first n_qubits values\n",
    "    for i, val in enumerate(x[:n_qubits]):\n",
    "        qml.RY(scale_to_angles(val), wires=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44efeb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compose: input -> encoder(phi) -> decoder(theta*) -> measure signal wires\n",
    "@qml.qnode(dev, interface=\"autograd\", diff_method=\"backprop\")\n",
    "def denoiser_qnode(phi, x_noisy):\n",
    "    embed_input(x_noisy)\n",
    "    encoder_template(phi)                     # compress\n",
    "    decoder_template(trained_dec_params)      # reconstruct with fixed decoder\n",
    "    return [qml.expval(qml.PauliZ(w)) for w in signal_wires]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c559fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss function: MSE between clean targets and decoded predictions (kept as pnp ops)\n",
    "def batch_loss(phi, clean_batch, noisy_batch):\n",
    "    preds = []\n",
    "    tgts  = []\n",
    "    for c, n in zip(clean_batch, noisy_batch):\n",
    "        y = pnp.array(denoiser_qnode(phi, n))  # shape (len(signal_wires),)\n",
    "        y = scale_back(y, info)\n",
    "        preds.append(y)\n",
    "        tgts.append(pnp.array(c)[signal_wires])\n",
    "    preds = pnp.stack(preds, axis=0)\n",
    "    tgts  = pnp.stack(tgts, axis=0)\n",
    "    return pnp.mean((preds - tgts) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1dd96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameter initialization: start from the true adjoint of decoder (good starting point)\n",
    "# For single-qubit Euler angles RX(a)RY(b)RZ(c), the inverse is RZ(-c) RY(-b) RX(-a).\n",
    "# However, because we built encoder via qml.adjoint(decoder_template)(phi),\n",
    "# the *matching* seed is simply phi = trained_dec_params (up to sign handled by adjoint).\n",
    "phi0 = pnp.array(trained_dec_params, requires_grad=True)\n",
    "print(\"Encoder params initialized from decoder (adjoint-compatible).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff09b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: simple noise model for augmentation\n",
    "def ts_add_noise(y, noise_level=0.05):\n",
    "    rng = info['scale_high'] - info['scale_low']\n",
    "    noise = noise_level * rng * np.random.randn(*np.array(y).shape)\n",
    "    return pnp.array(y) + noise\n",
    "\n",
    "# Prepare a tiny synthetic demo if your variables are not already in memory.\n",
    "# If you *already* have: pure_train_windows, pure_val_windows, set USE_DEMO = False.\n",
    "USE_DEMO = 'pure_train_windows' not in globals()\n",
    "if USE_DEMO:\n",
    "    print(\"No dataset detected in memory. Creating a tiny synthetic demo (sine).\")\n",
    "    xs = np.linspace(0, 2*np.pi, n_qubits)\n",
    "    clean_series = [0.5 + 0.5*np.sin(xs + phi) for phi in np.linspace(0, 2*np.pi, 128)]\n",
    "    pure_train_windows = np.array(clean_series[:96])\n",
    "    pure_val_windows   = np.array(clean_series[96:])\n",
    "else:\n",
    "    print(\"Using in-memory dataset: pure_train_windows / pure_val_windows\")\n",
    "\n",
    "print(\"Train windows shape:\", np.array(pure_train_windows).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a3071",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sanity check: with phi=trained_dec_params (ideal adjoint), the pipeline should be close to identity on signal_wires\n",
    "def sanity_identity(phi):\n",
    "    xs = np.linspace(0, 2*np.pi, 16)\n",
    "    clean = [0.5 + 0.5*np.sin(xs + a) for a in np.linspace(0, 2*np.pi, 24)]\n",
    "    errs = []\n",
    "    for w in clean:\n",
    "        y = pnp.array(denoiser_qnode(phi, w))\n",
    "        y = scale_back(y, info)\n",
    "        tgt = pnp.array(w)[signal_wires]\n",
    "        errs.append(pnp.mean((y - tgt)**2))\n",
    "    return float(pnp.mean(pnp.stack(errs)))\n",
    "\n",
    "mse_id = sanity_identity(trained_dec_params)\n",
    "mse_init = sanity_identity(phi0)\n",
    "print(f\"Sanity MSE with phi=decoder params (ideal adjoint seed): {mse_id:.6f}\")\n",
    "print(f\"Sanity MSE with phi0 (our init): {mse_init:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d29d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop (Adam on autograd)\n",
    "opt = qml.AdamOptimizer(stepsize=0.004)\n",
    "n_epochs = 60\n",
    "batch_size = 32\n",
    "\n",
    "def iterate_minibatches(X, B):\n",
    "    idx = np.random.permutation(len(X))\n",
    "    for i in range(0, len(X), B):\n",
    "        yield idx[i:i+B]\n",
    "\n",
    "phi = phi0\n",
    "best_val = float(\"inf\")\n",
    "best_phi = None\n",
    "patience = 10\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Training\n",
    "    train_cost = 0.0; batches = 0\n",
    "    for idx in iterate_minibatches(pure_train_windows, batch_size):\n",
    "        clean_batch = pure_train_windows[idx]\n",
    "        noisy_batch = [ts_add_noise(w, np.random.uniform(0.03, 0.08)) for w in clean_batch]\n",
    "        def loss_fn(p): return batch_loss(p, clean_batch, noisy_batch)\n",
    "        phi, cost = opt.step_and_cost(loss_fn, phi)\n",
    "        train_cost += cost; batches += 1\n",
    "    train_cost /= max(batches, 1)\n",
    "\n",
    "    # Validation (no noise)\n",
    "    val_preds = []\n",
    "    val_tgts  = []\n",
    "    for w in pure_val_windows:\n",
    "        y = pnp.array(denoiser_qnode(phi, w))\n",
    "        y = scale_back(y, info)\n",
    "        val_preds.append(y)\n",
    "        val_tgts.append(pnp.array(w)[signal_wires])\n",
    "    val_preds = pnp.stack(val_preds, axis=0)\n",
    "    val_tgts  = pnp.stack(val_tgts,  axis=0)\n",
    "    val_cost = float(pnp.mean((val_preds - val_tgts)**2))\n",
    "\n",
    "    # Simple scheduler / early stop\n",
    "    if val_cost + 1e-6 < best_val:\n",
    "        best_val = val_cost\n",
    "        best_phi = phi\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | train {train_cost:.6f} | val {val_cost:.6f}\")\n",
    "\n",
    "phi_trained = best_phi if best_phi is not None else phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843df492",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the trained encoder parameters\n",
    "out = {\n",
    "    \"encoder_params\": list(map(float, np.array(phi_trained))),\n",
    "    \"n_qubits\": n_qubits,\n",
    "    \"n_latent\": n_latent,\n",
    "    \"signal_wires\": signal_wires,\n",
    "    \"trash_wires\": trash_wires,\n",
    "}\n",
    "out_path = os.path.join(DATA_PATH, data_folder, \"adjoint_encoder_qae_model_trained.json\")\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "print(\"Saved:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
