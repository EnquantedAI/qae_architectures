{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54384db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 0 — Config (Monolith QAE, 6q_2l_4t, tau17)\n",
    "# ===========================\n",
    "import numpy as np\n",
    "DATA_ID = 'mackey_glass_tau17_n200'\n",
    "\n",
    "# Architecture (6q = 2 latent + 4 trash)\n",
    "wind_size = 4\n",
    "wind_step = 2\n",
    "n_latent = 2\n",
    "n_trash = wind_size - n_latent  # = 4\n",
    "n_extra = 0\n",
    "\n",
    "# Ansatz\n",
    "rot = 'Rxyz'\n",
    "\n",
    "# Training instances\n",
    "LAYER_OPTIONS = [3]\n",
    "INSTANCES_PER_LAYER = [1]\n",
    "\n",
    "# Data parameters\n",
    "noise = 0.2\n",
    "split = 0.75\n",
    "data_low = 0\n",
    "data_high = 1\n",
    "\n",
    "# Encoding/decoding ranges\n",
    "y_margin = 0.0\n",
    "y_enc_low, y_enc_high = 0 + y_margin, np.pi/4 - y_margin\n",
    "y_dec_low, y_dec_high = 0 + y_margin, np.pi/4 - y_margin\n",
    "noise_clip = True\n",
    "\n",
    "# Simulator settings\n",
    "sim = 'lightning.qubit'\n",
    "interface = 'autograd'\n",
    "diff_method = 'adjoint'\n",
    "shots = None\n",
    "\n",
    "# Training parameters\n",
    "n_epochs = 300\n",
    "lr_initial = 0.1\n",
    "lr_decay_rate = 0.75\n",
    "lr_decay_steps = 60\n",
    "log_interv = 1\n",
    "weight_scaler = 0.1\n",
    "batch_size = 10\n",
    "\n",
    "# Seeds\n",
    "TRAIN_SEED_BASE = 88000\n",
    "TEST_SEED_FIXED = 99123\n",
    "\n",
    "# Paths (relative to Monolith_QAE folder)\n",
    "BUNDLE_ROOT = '../../qae_runs'\n",
    "\n",
    "# Derived parameters\n",
    "n_data = n_latent + n_trash\n",
    "n_wires = n_latent + 2*n_trash + 2*n_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2952657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 1 — Imports & Utilities\n",
    "# ===========================\n",
    "import sys, os, time, random, json, csv\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "# Add paths to find qae_utils\n",
    "sys.path.append('../../..')\n",
    "sys.path.append('../../../..')\n",
    "\n",
    "# QAE utilities\n",
    "from qae_utils.Files import create_folder_if_needed, read_json_file, read_ts_file\n",
    "from qae_utils.Window import ts_wind_make, ts_wind_split, ts_wind_flatten_avg, ts_add_noise\n",
    "from qae_utils.Charts import multi_plot_flat_ts, meas_plot\n",
    "from qae_utils.Tools import draw_circuit\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "\n",
    "# Create necessary folders\n",
    "create_folder_if_needed(BUNDLE_ROOT)\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=6)\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def set_global_seed(instance_id: int):\n",
    "    \"\"\"Set reproducible seeds for training instance\"\"\"\n",
    "    base = 10_000 + int(instance_id)\n",
    "    random.seed(base + 11)\n",
    "    np.random.seed(base + 22)\n",
    "    try:\n",
    "        pnp.random.seed(base + 33)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return dict(global_seed=base, numpy_seed=base+22, pnp_seed=base+33)\n",
    "\n",
    "def arch_tag():\n",
    "    \"\"\"Generate architecture tag string\"\"\"\n",
    "    return f\"{wind_size}q_{n_latent}l_{n_trash}t\"\n",
    "\n",
    "def x2y(x, xlim=(0, 1), ylim=(0, np.pi)):\n",
    "    \"\"\"Scale values from xlim range to ylim range\"\"\"\n",
    "    low_x, high_x = xlim\n",
    "    low_y, high_y = ylim\n",
    "    input_range_length = high_x - low_x\n",
    "    if np.isclose(input_range_length, 0.0):\n",
    "        return (low_y + high_y) / 2\n",
    "    scaling_factor = (high_y - low_y) / input_range_length\n",
    "    return low_y + (x - low_x) * scaling_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d9339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 2 — Load Data\n",
    "# ===========================\n",
    "def _find_data_folder(data_id):\n",
    "    \"\"\"Find data folder with robust path searching\"\"\"\n",
    "    # New structure: ~/dev/data/{dataset_name}/\n",
    "    candidates = [\n",
    "        f'../../../data/{data_id}',  # From notebook location up to ~/dev/data/\n",
    "        f'../../data/{data_id}',     # Alternative\n",
    "        f'../data/{data_id}',        # Alternative\n",
    "    ]\n",
    "    \n",
    "    tried = []\n",
    "    for folder in candidates:\n",
    "        abs_path = os.path.abspath(folder)\n",
    "        tried.append(abs_path)\n",
    "        info_p = os.path.join(folder, 'info.json')\n",
    "        x_p = os.path.join(folder, 'x_org.arr')\n",
    "        y_p = os.path.join(folder, 'y_org.arr')\n",
    "        \n",
    "        if os.path.exists(info_p) and os.path.exists(x_p) and os.path.exists(y_p):\n",
    "            return folder\n",
    "    \n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not find dataset: {data_id}\\n\"\n",
    "        f\"Tried paths:\\n\" + \"\\n\".join(f\"  - {p}\" for p in tried)\n",
    "    )\n",
    "\n",
    "DATA_FOLDER = _find_data_folder(DATA_ID)\n",
    "info = read_json_file(f'{DATA_FOLDER}/info.json')\n",
    "X = read_ts_file(f'{DATA_FOLDER}/x_org.arr').astype(int)\n",
    "y = read_ts_file(f'{DATA_FOLDER}/y_org.arr')\n",
    "\n",
    "scale_low = float(info['scale_low'])\n",
    "scale_high = float(info['scale_high'])\n",
    "\n",
    "print(f'Data folder: {os.path.abspath(DATA_FOLDER)}')\n",
    "print(f'Loaded {len(y)} samples; scale=[{scale_low:.3f}, {scale_high:.3f}]')\n",
    "\n",
    "# Plot original data\n",
    "multi_plot_flat_ts([y], X_list=[0], colors=['blue'], labels=['Original'],\n",
    "                   lines=['solid'], legend_cols=1, rcParams=(10, 3),\n",
    "                   xlabel=f'Range (samples={len(y)})',\n",
    "                   title=f'Monolith QAE Training Data ({DATA_ID})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6ca39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 3 — Full QAE Architecture\n",
    "# ===========================\n",
    "def full_qae_shape(n_latent, n_trash, n_extra=0, n_layers=1, rot='Rxyz'):\n",
    "    \"\"\"Calculate weight shape for full QAE\"\"\"\n",
    "    n_wires = n_latent + n_trash + n_extra\n",
    "    if rot == 'Ry':\n",
    "        return qml.BasicEntanglerLayers.shape(n_layers=n_layers*2, n_wires=n_wires)\n",
    "    elif rot == 'Rxyz':\n",
    "        return qml.StronglyEntanglingLayers.shape(n_layers=n_layers*2, n_wires=n_wires)\n",
    "\n",
    "def full_qae(wires, n_latent, n_trash, n_extra, n_layers=1, rot='Rxyz', \n",
    "             add_outseq=False, invert_dec=True):\n",
    "    \"\"\"\n",
    "    Create full QAE circuit with SWAP-based reset\n",
    "    Returns: QNode-compatible callable\n",
    "    \"\"\"\n",
    "    n_data = n_latent + n_trash\n",
    "    n_anz = n_data + n_extra\n",
    "    n_zero = n_trash + n_extra\n",
    "    \n",
    "    latent_wires = wires[0:n_latent]\n",
    "    trash_wires = wires[n_latent:n_latent+n_trash]\n",
    "    extra_wires = wires[n_data:n_data+n_extra]\n",
    "    zero_wires = wires[n_anz:n_anz+n_zero]\n",
    "    data_wires = latent_wires + trash_wires\n",
    "    anz_wires = latent_wires + trash_wires + extra_wires\n",
    "\n",
    "    def _sequence_encoder(wires, inputs):\n",
    "        \"\"\"Angle embedding of input sequence\"\"\"\n",
    "        qml.AngleEmbedding(inputs, wires=wires, rotation='Y')\n",
    "\n",
    "    def _entangler_shape(n_layers, n_wires, rot='Rxyz'):\n",
    "        \"\"\"Get shape for entangling layer\"\"\"\n",
    "        if rot == 'Ry':\n",
    "            return qml.BasicEntanglerLayers.shape(n_layers=n_layers, n_wires=n_wires)\n",
    "        elif rot == 'Rxyz':\n",
    "            return qml.StronglyEntanglingLayers.shape(n_layers=n_layers, n_wires=n_wires)\n",
    "\n",
    "    def _entangler(wires, weights, rot='Rxyz'):\n",
    "        \"\"\"Apply entangling layers\"\"\"\n",
    "        if rot == 'Ry':\n",
    "            qml.BasicEntanglerLayers(weights, wires=wires, rotation=qml.RY)\n",
    "        elif rot == 'Rxyz':\n",
    "            qml.StronglyEntanglingLayers(weights, wires=wires)\n",
    "\n",
    "    def _swap(from_wires, to_wires):\n",
    "        \"\"\"Apply SWAP gates\"\"\"\n",
    "        for i in range(len(from_wires)):\n",
    "            qml.SWAP(wires=[from_wires[i], to_wires[i]])\n",
    "\n",
    "    def _full_qae(weights, inputs):\n",
    "        \"\"\"Full QAE circuit\"\"\"\n",
    "        # Input encoding\n",
    "        _sequence_encoder(data_wires, inputs)\n",
    "        qml.Barrier(wires)\n",
    "\n",
    "        # Get weight shapes\n",
    "        enc_weights_shape = _entangler_shape(n_layers, len(anz_wires), rot=rot)\n",
    "        dec_weights_shape = enc_weights_shape\n",
    "\n",
    "        # Split weights\n",
    "        enc_weights = weights[:n_layers].reshape(enc_weights_shape)\n",
    "        dec_weights = weights[n_layers:].reshape(dec_weights_shape)\n",
    "\n",
    "        # Encoder\n",
    "        _entangler(anz_wires, enc_weights, rot=rot)\n",
    "\n",
    "        # SWAP reset\n",
    "        qml.Barrier(wires)\n",
    "        _swap(trash_wires + extra_wires, zero_wires)\n",
    "        qml.Barrier(wires)\n",
    "\n",
    "        # Decoder\n",
    "        if invert_dec:\n",
    "            qml.adjoint(_entangler)(anz_wires, dec_weights, rot=rot)\n",
    "        else:\n",
    "            _entangler(anz_wires, enc_weights, rot=rot)\n",
    "        qml.Barrier(wires)\n",
    "\n",
    "        # Optional output sequence\n",
    "        if add_outseq:\n",
    "            qml.adjoint(_sequence_encoder)(data_wires, inputs)\n",
    "\n",
    "        return [qml.expval(qml.PauliZ(wires=w)) for w in data_wires]\n",
    "\n",
    "    return _full_qae\n",
    "\n",
    "shape = full_qae_shape(n_latent, n_trash, n_extra, n_layers=1, rot=rot)\n",
    "print(f'Base QAE shape (per layer): {shape}')\n",
    "print(f'Architecture: {arch_tag()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b3140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 4 — Training Functions\n",
    "# ===========================\n",
    "def get_mini_batches(W_noisy, W_clean, batch_size=10, shuffle=True, seed=0):\n",
    "    \"\"\"Generate mini-batches for training\"\"\"\n",
    "    if seed == 0:\n",
    "        seed = int(time.time()*1000) % 10000\n",
    "    np.random.seed(seed)\n",
    "    num_samples = W_clean.shape[0]\n",
    "    indices = np.arange(num_samples)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "    \n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_indices = indices[i:i + batch_size]\n",
    "        yield W_noisy[batch_indices], W_clean[batch_indices]\n",
    "\n",
    "def create_sw_tens(X, y, noise=0.0, wind_size=5, wind_step=2, \n",
    "                   range_low=0.2, range_high=0.8, seed=0, noise_clip=True):\n",
    "    \"\"\"Create sliding window tensors with optional noise\"\"\"\n",
    "    y_noisy = ts_add_noise(y, noise=noise, noise_type='normal', clip=noise_clip,\n",
    "                          range_low=range_low, range_high=range_high, seed=seed)\n",
    "    y_ts = ts_wind_make(y_noisy, wind_size, wind_step)\n",
    "    X_ts = ts_wind_make(X, wind_size, wind_step)\n",
    "    X_train_ts, y_train_ts, X_test_ts, y_test_ts = ts_wind_split(X_ts, y_ts, split)\n",
    "    \n",
    "    X_train_tens = pnp.array(X_train_ts, requires_grad=False)\n",
    "    y_train_tens = pnp.array(y_train_ts, requires_grad=False)\n",
    "    X_test_tens = pnp.array(X_test_ts, requires_grad=False)\n",
    "    y_test_tens = pnp.array(y_test_ts, requires_grad=False)\n",
    "    return X_train_tens, y_train_tens, X_test_tens, y_test_tens\n",
    "\n",
    "def mse_cost_on_tensors(targets, predictions):\n",
    "    \"\"\"MSE cost function (gradient-friendly)\"\"\"\n",
    "    cost = 0\n",
    "    vals = 0\n",
    "    for i in range(len(targets)):\n",
    "        for w in range(len(targets[i])):\n",
    "            cost = cost + (targets[i][w] - predictions[i][w]) ** 2\n",
    "            vals += 1\n",
    "    return cost / vals\n",
    "\n",
    "def cost_fun_gen_on_tensors(model, cost_fun):\n",
    "    \"\"\"Generate cost function for model\"\"\"\n",
    "    def _cost_fun(params, inputs, targets):\n",
    "        preds = [model(params, x) for x in inputs]\n",
    "        return cost_fun(targets, preds)\n",
    "    return _cost_fun\n",
    "\n",
    "def train_with_noise(model, W, cost_fun, optimizer, n_epochs, init_weights=None,\n",
    "                     log_interv=1, prompt_fract=0.1, start_time=0, seed=0,\n",
    "                     wind_size=8, wind_step=4, noise=0, \n",
    "                     enc_lim=(0, 1), dec_lim=(0, 1)):\n",
    "    \"\"\"Train model with noisy mini-batches\"\"\"\n",
    "    enc_low, enc_high = enc_lim\n",
    "    dec_low, dec_high = dec_lim\n",
    "    \n",
    "    if seed == 0:\n",
    "        seed = int(time.time()*1000) % 10000\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    hist_cost = []\n",
    "    hist_params = []\n",
    "    params = init_weights.copy()\n",
    "    \n",
    "    # Prepare pure targets\n",
    "    _, y_pure, _, _ = create_sw_tens(W, W, noise=0, wind_size=wind_size, \n",
    "                                     wind_step=wind_step, range_low=enc_low, \n",
    "                                     range_high=enc_high)\n",
    "    y_pure = x2y(y_pure, xlim=(enc_low, enc_high), ylim=(dec_low, dec_high))\n",
    "    \n",
    "    if start_time == 0:\n",
    "        start_time = time.time()\n",
    "    \n",
    "    for iter in range(n_epochs):\n",
    "        # Generate noisy inputs\n",
    "        _, X_noisy, _, _ = create_sw_tens(W, W, noise=noise, seed=seed+iter,\n",
    "                                          noise_clip=noise_clip, wind_size=wind_size,\n",
    "                                          wind_step=wind_step, range_low=enc_low,\n",
    "                                          range_high=enc_high)\n",
    "        \n",
    "        # Decay learning rate\n",
    "        if (iter+1) % lr_decay_steps == 0:\n",
    "            optimizer.stepsize *= lr_decay_rate\n",
    "        \n",
    "        # Mini-batch training\n",
    "        batches = get_mini_batches(X_noisy, y_pure, batch_size=batch_size, \n",
    "                                   shuffle=True, seed=seed+iter)\n",
    "        acc_batch_cost = 0\n",
    "        for batch_no, (noisy_batch, pure_batch) in enumerate(batches):\n",
    "            params, batch_cost = optimizer.step_and_cost(\n",
    "                lambda p: cost_fun(p, noisy_batch, pure_batch), params)\n",
    "            acc_batch_cost += batch_cost\n",
    "        cost = acc_batch_cost / (batch_no + 1)\n",
    "        \n",
    "        # Logging\n",
    "        if iter % log_interv == 0:\n",
    "            hist_cost.append(cost)\n",
    "            hist_params.append(params)\n",
    "        \n",
    "        if (prompt_fract > 0) and (iter % int(prompt_fract*n_epochs) == 0):\n",
    "            elapsed = int(time.time() - start_time)\n",
    "            print(f'Iter: {iter:03d} ({elapsed:04d} sec) cost={cost:0.6f}, ' +\n",
    "                  f'min={np.min(hist_cost):0.6f} (LR={optimizer.stepsize:0.4f})')\n",
    "    \n",
    "    min_cost = np.min(hist_cost)\n",
    "    min_iter = np.argmin(hist_cost)\n",
    "    elapsed = int(time.time() - start_time)\n",
    "    print(f'\\nCompleted: epochs={n_epochs}, min cost={min_cost:.6f} @ {min_iter}, ' +\n",
    "          f'time={elapsed} sec\\n')\n",
    "    \n",
    "    return hist_cost, hist_params, init_weights, (min_iter, min_cost, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c24fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 5 — Evaluation Functions\n",
    "# ===========================\n",
    "def _flatten_avg(windows):\n",
    "    \"\"\"Flatten overlapping windows by averaging\"\"\"\n",
    "    return ts_wind_flatten_avg(np.asarray(windows), wind_step)\n",
    "\n",
    "def _mse(a, b):\n",
    "    \"\"\"Calculate MSE between two sequences\"\"\"\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "    return float(np.mean((a - b) ** 2))\n",
    "\n",
    "def windows_from_seed(y_vec, sigma, seed):\n",
    "    \"\"\"Generate clean and noisy windows with fixed seed\"\"\"\n",
    "    y_noisy = ts_add_noise(y_vec, noise=sigma, noise_type='normal', clip=False,\n",
    "                          range_low=scale_low, range_high=scale_high, seed=seed)\n",
    "    win_clean = ts_wind_make(y_vec, wind_size, wind_step)\n",
    "    win_noisy = ts_wind_make(y_noisy, wind_size, wind_step)\n",
    "    X_ts = np.array([i*wind_step for i in range(len(win_clean))])\n",
    "    _, tr_clean, _, te_clean = ts_wind_split(X_ts, win_clean, split)\n",
    "    _, tr_noisy, _, te_noisy = ts_wind_split(X_ts, win_noisy, split)\n",
    "    return tr_clean, tr_noisy, te_clean, te_noisy\n",
    "\n",
    "def run_qnode_series(model, params, windows):\n",
    "    \"\"\"Run model on series of windows\"\"\"\n",
    "    outs = []\n",
    "    for w in windows:\n",
    "        z = model(params, w)\n",
    "        outs.append(np.asarray(z))\n",
    "    return np.stack(outs)\n",
    "\n",
    "def render_circuit(L, weights_vec, save_dir, inst):\n",
    "    \"\"\"Render and save circuit diagram\"\"\"\n",
    "    wires = list(range(n_wires))\n",
    "    qae = full_qae(wires, n_latent, n_trash, n_extra, n_layers=L, \n",
    "                   rot=rot, add_outseq=False, invert_dec=True)\n",
    "    dev = qml.device(sim, wires=n_wires, shots=shots)\n",
    "    qnode = qml.QNode(qae, dev)\n",
    "    \n",
    "    x_dummy = np.zeros(wind_size, dtype=float)\n",
    "    qml.drawer.use_style(\"pennylane\")\n",
    "    fig_func = qml.draw_mpl(qnode, decimals=2, level=\"device\")\n",
    "    fig, ax = fig_func(weights_vec, x_dummy)\n",
    "    ax.set_title(f'Monolith QAE (L={L}, inst={inst})')\n",
    "    \n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_png = save_dir / f\"circuit_{arch_tag()}_L{L}_inst{inst:02d}.png\"\n",
    "    fig.savefig(out_png, dpi=220, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "    plt.close(fig)\n",
    "    return out_png\n",
    "\n",
    "def plot_reconstruction(X_coords_train, X_coords_test, \n",
    "                       y_pure_train, y_pure_test,\n",
    "                       y_noisy_train, y_noisy_test,\n",
    "                       y_rec_train, y_rec_test,\n",
    "                       mse_train_noise, mse_test_noise,\n",
    "                       mse_train_rec, mse_test_rec,\n",
    "                       title_suffix=\"\", save_path=None):\n",
    "    \"\"\"Plot reconstruction results from pure data\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot noisy data\n",
    "    plt.plot(X_coords_train, y_noisy_train, color=\"lightblue\", linestyle='', \n",
    "             mfc='white', marker='.', label=f\"Noisy train (MSE {mse_train_noise:0.4f})\")\n",
    "    plt.plot(X_coords_test, y_noisy_test, color=\"pink\", linestyle='', \n",
    "             mfc='white', marker='.', label=f\"Noisy test  (MSE {mse_test_noise:0.4f})\")\n",
    "    \n",
    "    # Plot pure data\n",
    "    plt.plot(X_coords_train, y_pure_train, label=\"True train\", color=\"cornflowerblue\")\n",
    "    plt.plot(X_coords_test, y_pure_test, label=\"True test\", color=\"salmon\")\n",
    "    \n",
    "    # Plot recovered data\n",
    "    plt.plot(X_coords_train, y_rec_train, color=\"blue\", linestyle='dashed', \n",
    "             label=f\"Recovered train (MSE {mse_train_rec:0.4f})\")\n",
    "    plt.plot(X_coords_test, y_rec_test, color=\"red\", linestyle='dashed', \n",
    "             label=f\"Recovered test  (MSE {mse_test_rec:0.4f})\")\n",
    "    \n",
    "    # Train/test split line\n",
    "    plt.axvline(x=(X_coords_train[-1]+X_coords_test[0])/2, \n",
    "                color=\"lightgray\", linestyle='dashed')\n",
    "    \n",
    "    plt.xlabel(f'Time (windows: size={wind_size}, step={wind_step})')\n",
    "    plt.ylabel('y Values')\n",
    "    plt.title(f'Pure data vs recovered {title_suffix}')\n",
    "    plt.legend(loc='lower left', ncol=3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e18a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 6 — Multi-Instance Training\n",
    "# ===========================\n",
    "import pandas as pd\n",
    "\n",
    "def ensure_dir(p):\n",
    "    \"\"\"Create directory if it doesn't exist\"\"\"\n",
    "    p = Path(p)\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "# Setup directory structure\n",
    "ROOT = ensure_dir(BUNDLE_ROOT)\n",
    "DATA_ROOT = ensure_dir(ROOT / DATA_ID)\n",
    "ARCH_ROOT = ensure_dir(DATA_ROOT / arch_tag())\n",
    "CSV_RUNS = ARCH_ROOT / \"metrics_by_run.csv\"\n",
    "CSV_SUMMARY = ARCH_ROOT / \"summary_by_layer.csv\"\n",
    "\n",
    "RUNS_HEADER = [\n",
    "    \"dataset\", \"arch\", \"instance_id\", \"layer\",\n",
    "    \"window_size\", \"step\", \"sigma_eval\",\n",
    "    \"mse_train_noise\", \"mse_train_recovered\", \"delta_train_pct\",\n",
    "    \"mse_test_noise\", \"mse_test_recovered\", \"delta_test_pct\",\n",
    "    \"min_train_cost\", \"training_time_sec\", \"timestamp\", \"bundle_json\"\n",
    "]\n",
    "\n",
    "if not CSV_RUNS.exists():\n",
    "    with open(CSV_RUNS, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        csv.writer(f).writerow(RUNS_HEADER)\n",
    "\n",
    "ALL_RUNS = []\n",
    "\n",
    "for L in LAYER_OPTIONS:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"TRAINING LAYER {L}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Get shape for this layer count\n",
    "    shp = full_qae_shape(n_latent, n_trash, n_extra, n_layers=L, rot=rot)\n",
    "    \n",
    "    # Create model\n",
    "    wires = list(range(n_wires))\n",
    "    dev = qml.device(sim, wires=n_wires, shots=shots)\n",
    "    qae = full_qae(wires, n_latent, n_trash, n_extra, n_layers=L,\n",
    "                   rot=rot, add_outseq=False, invert_dec=True)\n",
    "    qae_model = qml.QNode(qae, dev, interface=interface, diff_method=diff_method)\n",
    "    qae_model.shape = shp\n",
    "    \n",
    "    layer_dir = ensure_dir(ARCH_ROOT / f\"L{L}\")\n",
    "    \n",
    "    for inst in INSTANCES_PER_LAYER:\n",
    "        print(f\"\\n--- Layer {L} | Instance {inst} ---\")\n",
    "        \n",
    "        # Set reproducible seed\n",
    "        set_global_seed(inst)\n",
    "        \n",
    "        # Initialize optimizer and weights\n",
    "        opt = qml.AdamOptimizer(stepsize=lr_initial, beta1=0.99)\n",
    "        init_weights = pnp.array(np.random.uniform(high=2*np.pi, size=shp) * weight_scaler, \n",
    "                                 requires_grad=True)\n",
    "        \n",
    "        # Define cost function\n",
    "        cost_fun = cost_fun_gen_on_tensors(qae_model, mse_cost_on_tensors)\n",
    "        \n",
    "        # Prepare encoded data\n",
    "        y_enc = x2y(y, xlim=(scale_low, scale_high), ylim=(y_enc_low, y_enc_high))\n",
    "        \n",
    "        # Train\n",
    "        hist_cost, hist_params, _, (min_iter, min_cost, elapsed) = train_with_noise(\n",
    "            qae_model, y_enc, cost_fun, opt, n_epochs, init_weights,\n",
    "            log_interv=log_interv, prompt_fract=0.1, seed=TRAIN_SEED_BASE,\n",
    "            wind_size=wind_size, wind_step=wind_step, noise=noise,\n",
    "            enc_lim=(y_enc_low, y_enc_high), dec_lim=(y_dec_low, y_dec_high)\n",
    "        )\n",
    "        \n",
    "        # Get optimal parameters\n",
    "        opt_params = hist_params[min_iter]\n",
    "        weights_np = np.array(opt_params)\n",
    "        \n",
    "        # Evaluate on test set (from noisy data)\n",
    "        tr_c, tr_n, te_c, te_n = windows_from_seed(y, noise, TEST_SEED_FIXED)\n",
    "        tr_n_enc = x2y(tr_n, xlim=(scale_low, scale_high), ylim=(y_enc_low, y_enc_high))\n",
    "        te_n_enc = x2y(te_n, xlim=(scale_low, scale_high), ylim=(y_enc_low, y_enc_high))\n",
    "        \n",
    "        tr_hat = run_qnode_series(qae_model, opt_params, tr_n_enc)\n",
    "        te_hat = run_qnode_series(qae_model, opt_params, te_n_enc)\n",
    "        \n",
    "        # Also evaluate from pure data for comparison\n",
    "        tr_c_enc = x2y(tr_c, xlim=(scale_low, scale_high), ylim=(y_enc_low, y_enc_high))\n",
    "        te_c_enc = x2y(te_c, xlim=(scale_low, scale_high), ylim=(y_enc_low, y_enc_high))\n",
    "        tr_hat_pure = run_qnode_series(qae_model, opt_params, tr_c_enc)\n",
    "        te_hat_pure = run_qnode_series(qae_model, opt_params, te_c_enc)\n",
    "        \n",
    "        # Flatten all for metrics and plotting\n",
    "        tr_pure = _flatten_avg(tr_c); te_pure = _flatten_avg(te_c)\n",
    "        tr_noi = _flatten_avg(tr_n); te_noi = _flatten_avg(te_n)\n",
    "        tr_rec = x2y(_flatten_avg(tr_hat), xlim=(y_dec_low, y_dec_high), \n",
    "                     ylim=(scale_low, scale_high))\n",
    "        te_rec = x2y(_flatten_avg(te_hat), xlim=(y_dec_low, y_dec_high), \n",
    "                     ylim=(scale_low, scale_high))\n",
    "        tr_rec_pure = x2y(_flatten_avg(tr_hat_pure), xlim=(y_dec_low, y_dec_high), \n",
    "                          ylim=(scale_low, scale_high))\n",
    "        te_rec_pure = x2y(_flatten_avg(te_hat_pure), xlim=(y_dec_low, y_dec_high), \n",
    "                          ylim=(scale_low, scale_high))\n",
    "        \n",
    "        # Create coordinate arrays for plotting\n",
    "        n_train = len(tr_pure)\n",
    "        n_test = len(te_pure)\n",
    "        X_coords_train = np.arange(0, n_train * wind_step, wind_step)[:n_train]\n",
    "        X_coords_test = np.arange(n_train * wind_step, \n",
    "                                  n_train * wind_step + n_test * wind_step, \n",
    "                                  wind_step)[:n_test]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse_tr_noise = _mse(tr_pure, tr_noi)\n",
    "        mse_te_noise = _mse(te_pure, te_noi)\n",
    "        mse_tr_rec = _mse(tr_pure, tr_rec)\n",
    "        mse_te_rec = _mse(te_pure, te_rec)\n",
    "        mse_tr_rec_pure = _mse(tr_pure, tr_rec_pure)\n",
    "        mse_te_rec_pure = _mse(te_pure, te_rec_pure)\n",
    "        \n",
    "        delta_tr = 100.0 * (1.0 - mse_tr_rec / max(mse_tr_noise, 1e-12))\n",
    "        delta_te = 100.0 * (1.0 - mse_te_rec / max(mse_te_noise, 1e-12))\n",
    "        \n",
    "        print(f\"Test MSE: noise={mse_te_noise:.6f}, recovered={mse_te_rec:.6f}, \" +\n",
    "              f\"Δ={delta_te:+.2f}%\")\n",
    "        \n",
    "        # Save artifacts\n",
    "        inst_tag = f\"inst{inst:02d}_L{L}\"\n",
    "        np.save(layer_dir / f\"weights_{inst_tag}.npy\", weights_np)\n",
    "        circuit_path = render_circuit(L, weights_np, ARCH_ROOT, inst)\n",
    "        \n",
    "        # Plot training cost\n",
    "        cost_plot_path = layer_dir / f\"training_cost_{inst_tag}.png\"\n",
    "        meas_plot(hist_cost, meas='cost', task='min', \n",
    "                  title_pref=f'L{L} Instance {inst} Training', \n",
    "                  ylim=(0, max(0.15, max(hist_cost)*1.1)), rcParams=(10, 4), \n",
    "                  log_interv=log_interv, backplot=True, back_color='lightgray', \n",
    "                  smooth_weight=0.5)\n",
    "        plt.savefig(cost_plot_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot reconstruction from pure data\n",
    "        recon_pure_path = layer_dir / f\"reconstruction_pure_{inst_tag}.png\"\n",
    "        plot_reconstruction(\n",
    "            X_coords_train, X_coords_test,\n",
    "            tr_pure, te_pure, tr_noi, te_noi,\n",
    "            tr_rec_pure, te_rec_pure,\n",
    "            mse_tr_noise, mse_te_noise,\n",
    "            mse_tr_rec_pure, mse_te_rec_pure,\n",
    "            title_suffix=f\"from pure data (L={L}, inst={inst})\",\n",
    "            save_path=recon_pure_path\n",
    "        )\n",
    "        \n",
    "        # Plot reconstruction from noisy data\n",
    "        recon_noisy_path = layer_dir / f\"reconstruction_noisy_{inst_tag}.png\"\n",
    "        plot_reconstruction(\n",
    "            X_coords_train, X_coords_test,\n",
    "            tr_pure, te_pure, tr_noi, te_noi,\n",
    "            tr_rec, te_rec,\n",
    "            mse_tr_noise, mse_te_noise,\n",
    "            mse_tr_rec, mse_te_rec,\n",
    "            title_suffix=f\"from noisy data (L={L}, inst={inst})\",\n",
    "            save_path=recon_noisy_path\n",
    "        )\n",
    "        \n",
    "        # Create bundle\n",
    "        bundle = {\n",
    "            \"schema\": {\"name\": \"monolith_qae_bundle\", \"version\": \"1.0\"},\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"dataset\": {\n",
    "                \"id\": DATA_ID,\n",
    "                \"scale_low\": float(scale_low),\n",
    "                \"scale_high\": float(scale_high),\n",
    "                \"window_size\": int(wind_size),\n",
    "                \"window_step\": int(wind_step),\n",
    "                \"split\": float(split),\n",
    "            },\n",
    "            \"run\": {\n",
    "                \"instance_id\": int(inst),\n",
    "                \"layer\": int(L),\n",
    "                \"sigma_eval\": float(noise),\n",
    "                \"test_seed_fixed\": int(TEST_SEED_FIXED),\n",
    "                \"training_time_sec\": int(elapsed),\n",
    "            },\n",
    "            \"environment\": {\n",
    "                \"device\": sim,\n",
    "                \"diff_method\": diff_method,\n",
    "                \"interface\": interface,\n",
    "            },\n",
    "            \"architecture\": {\n",
    "                \"type\": \"monolith\",\n",
    "                \"n_qubits\": int(wind_size),\n",
    "                \"n_latent\": int(n_latent),\n",
    "                \"n_trash\": int(n_trash),\n",
    "                \"n_extra\": int(n_extra),\n",
    "                \"rot\": str(rot),\n",
    "            },\n",
    "            \"parameters\": {\n",
    "                \"weights\": weights_np.tolist(),\n",
    "            },\n",
    "            \"metrics\": {\n",
    "                \"mse_train_noise\": float(mse_tr_noise),\n",
    "                \"mse_train_recovered\": float(mse_tr_rec),\n",
    "                \"delta_train_pct\": float(delta_tr),\n",
    "                \"mse_test_noise\": float(mse_te_noise),\n",
    "                \"mse_test_recovered\": float(mse_te_rec),\n",
    "                \"delta_test_pct\": float(delta_te),\n",
    "                \"mse_train_recovered_pure\": float(mse_tr_rec_pure),\n",
    "                \"mse_test_recovered_pure\": float(mse_te_rec_pure),\n",
    "            },\n",
    "            \"artifacts\": {\n",
    "                \"weights_file\": f\"weights_{inst_tag}.npy\",\n",
    "                \"circuit_diagram\": str(circuit_path.name),\n",
    "                \"training_cost_plot\": str(cost_plot_path.name),\n",
    "                \"reconstruction_pure_plot\": str(recon_pure_path.name),\n",
    "                \"reconstruction_noisy_plot\": str(recon_noisy_path.name),\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        bundle_path = layer_dir / f\"bundle_{inst_tag}.json\"\n",
    "        with open(bundle_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(bundle, f, indent=2)\n",
    "        \n",
    "        # Save to CSV\n",
    "        row = [\n",
    "            DATA_ID, arch_tag(), int(inst), int(L),\n",
    "            int(wind_size), int(wind_step), float(noise),\n",
    "            mse_tr_noise, mse_tr_rec, delta_tr,\n",
    "            mse_te_noise, mse_te_rec, delta_te,\n",
    "            float(min_cost), int(elapsed), bundle[\"timestamp\"], str(bundle_path)\n",
    "        ]\n",
    "        \n",
    "        if CSV_RUNS.exists():\n",
    "            df_old = pd.read_csv(CSV_RUNS)\n",
    "            df_new = pd.concat([df_old, pd.DataFrame([row], columns=RUNS_HEADER)], \n",
    "                              ignore_index=True)\n",
    "            df_new.to_csv(CSV_RUNS, index=False)\n",
    "        else:\n",
    "            pd.DataFrame([row], columns=RUNS_HEADER).to_csv(CSV_RUNS, index=False)\n",
    "        \n",
    "        ALL_RUNS.append({\"instance_id\": inst, \"layer\": L, \"weights\": weights_np})\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"TRAINING COMPLETE\")\n",
    "print(f\"Metrics saved: {CSV_RUNS}\")\n",
    "print(f\"Artifacts saved: {ARCH_ROOT}\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Generate summary\n",
    "if CSV_RUNS.exists():\n",
    "    df = pd.read_csv(CSV_RUNS)\n",
    "    summary = (df.groupby(\"layer\", as_index=True)\n",
    "               .agg(runs=(\"instance_id\", \"count\"),\n",
    "                    avg_training_time=(\"training_time_sec\", \"mean\"),\n",
    "                    mse_test_noise_mean=(\"mse_test_noise\", \"mean\"),\n",
    "                    mse_test_recovered_mean=(\"mse_test_recovered\", \"mean\"),\n",
    "                    delta_test_pct_mean=(\"delta_test_pct\", \"mean\")))\n",
    "    summary.to_csv(CSV_SUMMARY)\n",
    "    print(f\"\\nSummary saved: {CSV_SUMMARY}\")\n",
    "    print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
