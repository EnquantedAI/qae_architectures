{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 0 — Config (Stacked QAE, 6q_4l_2t, tau30)\n",
    "# ===========================\n",
    "import numpy as np\n",
    "\n",
    "DATA_ID = 'mackey_glass_tau17_n200'\n",
    "\n",
    "# Architecture (4q = 3 latent + 1 trash)\n",
    "wind_size = 4\n",
    "wind_step = 2\n",
    "n_latent = 3\n",
    "n_trash = wind_size - n_latent  # = 1\n",
    "\n",
    "# Ansatz\n",
    "rot = 'Rxyz'\n",
    "\n",
    "# Training instances\n",
    "LAYER_OPTIONS = [1,3,4]\n",
    "INSTANCES_PER_LAYER = [1,2,3,4,5,6,7]\n",
    "\n",
    "# Data parameters\n",
    "noise = 0.2\n",
    "split = 0.75\n",
    "data_low = 0\n",
    "data_high = 1\n",
    "\n",
    "# Encoding/decoding ranges (no margin, clip noise instead)\n",
    "y_margin = 0.0\n",
    "y_enc_low, y_enc_high = -np.pi + y_margin, 0 - y_margin\n",
    "y_dec_low, y_dec_high = -1, +1\n",
    "noise_clip = True\n",
    "\n",
    "# Simulator settings\n",
    "sim = 'lightning.qubit'\n",
    "interface = 'autograd'\n",
    "diff_method = 'adjoint'\n",
    "shots = None\n",
    "\n",
    "# Training parameters - Stage 1 (Inverted Decoder)\n",
    "n_inv_decoder_epochs = 500\n",
    "lr_inv_decoder_initial = 0.02\n",
    "inv_decoder_weight_scaler = 0.05\n",
    "\n",
    "# Training parameters - Stage 2 (Stacked)\n",
    "n_stacked_epochs = 300\n",
    "lr_stacked_initial = 0.1\n",
    "lr_stacked_decay_rate = 0.75\n",
    "lr_stacked_decay_steps = 50\n",
    "stacked_weight_scaler = 0.1\n",
    "batch_size = 10\n",
    "\n",
    "# Seeds\n",
    "TRAIN_SEED_BASE = 88000\n",
    "TEST_SEED_FIXED = 99123\n",
    "\n",
    "# Paths (relative to Stacked_QAE folder)\n",
    "BUNDLE_ROOT = '../../qae_runs'\n",
    "\n",
    "# Derived parameters\n",
    "n_wires_full = n_latent + 2*n_trash\n",
    "log_interv = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 1 — Imports & Utilities\n",
    "# ===========================\n",
    "import sys, os, time, random, json, csv\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "# Add paths to find qae_utils\n",
    "sys.path.append('../../..')\n",
    "sys.path.append('../../../..')\n",
    "\n",
    "# QAE utilities\n",
    "from qae_utils.Files import create_folder_if_needed, read_json_file, read_ts_file\n",
    "from qae_utils.Window import ts_wind_make, ts_wind_split, ts_wind_flatten_avg, ts_add_noise\n",
    "from qae_utils.Charts import multi_plot_flat_ts, meas_plot\n",
    "from qae_utils.Tools import draw_circuit\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "import torch\n",
    "\n",
    "# Create necessary folders\n",
    "create_folder_if_needed(BUNDLE_ROOT)\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=6)\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Cell 1 — Update set_global_seed function\n",
    "\n",
    "def set_global_seed(instance_id: int, layer: int = None):\n",
    "    \"\"\"Set reproducible seeds for training instance\"\"\"\n",
    "    if layer is not None:\n",
    "        base = 10_000 + int(layer) * 1000 + int(instance_id)\n",
    "    else:\n",
    "        base = 10_000 + int(instance_id)\n",
    "    \n",
    "    random.seed(base + 11)\n",
    "    np.random.seed(base + 22)\n",
    "    try:\n",
    "        pnp.random.seed(base + 33)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    device_seed = base + 44\n",
    "    \n",
    "    return {\n",
    "        'global_seed': base,\n",
    "        'numpy_seed': base + 22,\n",
    "        'pnp_seed': base + 33,\n",
    "        'device_seed': device_seed\n",
    "    }\n",
    "\n",
    "def arch_tag():\n",
    "    \"\"\"Generate architecture tag string\"\"\"\n",
    "    return f\"{wind_size}q_{n_latent}l_{n_trash}t_stacked\"\n",
    "\n",
    "def x2y(x, xlim=(0, 1), ylim=(0, np.pi)):\n",
    "    \"\"\"Scale values from xlim range to ylim range\"\"\"\n",
    "    low_x, high_x = xlim\n",
    "    low_y, high_y = ylim\n",
    "    input_range_length = high_x - low_x\n",
    "    if np.isclose(input_range_length, 0.0):\n",
    "        return (low_y + high_y) / 2\n",
    "    scaling_factor = (high_y - low_y) / input_range_length\n",
    "    return low_y + (x - low_x) * scaling_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 2 — Load Data\n",
    "# ===========================\n",
    "def _find_data_folder(data_id):\n",
    "    \"\"\"Find data folder with robust path searching\"\"\"\n",
    "    candidates = [\n",
    "        f'../../../data/{data_id}',\n",
    "        f'../../data/{data_id}',\n",
    "        f'../data/{data_id}',\n",
    "    ]\n",
    "    \n",
    "    tried = []\n",
    "    for folder in candidates:\n",
    "        abs_path = os.path.abspath(folder)\n",
    "        tried.append(abs_path)\n",
    "        info_p = os.path.join(folder, 'info.json')\n",
    "        x_p = os.path.join(folder, 'x_org.arr')\n",
    "        y_p = os.path.join(folder, 'y_org.arr')\n",
    "        \n",
    "        if os.path.exists(info_p) and os.path.exists(x_p) and os.path.exists(y_p):\n",
    "            return folder\n",
    "    \n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not find dataset: {data_id}\\n\"\n",
    "        f\"Tried paths:\\n\" + \"\\n\".join(f\"  - {p}\" for p in tried)\n",
    "    )\n",
    "\n",
    "DATA_FOLDER = _find_data_folder(DATA_ID)\n",
    "info = read_json_file(f'{DATA_FOLDER}/info.json')\n",
    "X = read_ts_file(f'{DATA_FOLDER}/x_org.arr').astype(int)\n",
    "y = read_ts_file(f'{DATA_FOLDER}/y_org.arr')\n",
    "\n",
    "scale_low = float(info['scale_low'])\n",
    "scale_high = float(info['scale_high'])\n",
    "\n",
    "print(f'Data folder: {os.path.abspath(DATA_FOLDER)}')\n",
    "print(f'Loaded {len(y)} samples; scale=[{scale_low:.3f}, {scale_high:.3f}]')\n",
    "\n",
    "# Plot original data\n",
    "multi_plot_flat_ts(\n",
    "    X_list=[X], \n",
    "    y_list=[y], \n",
    "    colors=['blue'], \n",
    "    labels=['Original'],\n",
    "    lines=['solid'], \n",
    "    legend_cols=1, \n",
    "    rcParams=(10, 3),\n",
    "    xlabel=f'Range (samples={len(y)})',\n",
    "    title=f'Stacked QAE Training Data ({DATA_ID})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa1cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 3 — Stacked QAE Architecture Components\n",
    "# ===========================\n",
    "\n",
    "def sequence_encoder(wires, inputs):\n",
    "    \"\"\"Encodes sequence (similar to AngleEncoding)\"\"\"\n",
    "    for i in range(len(wires)):\n",
    "        if i < len(inputs):\n",
    "            qml.RY(inputs[i], wires=wires[i])\n",
    "        else:\n",
    "            qml.RY(0, wires=wires[i])\n",
    "\n",
    "def entangler_shape(n_layers, n_wires, rot='Rxyz'):\n",
    "    \"\"\"Get shape for entangling layer\"\"\"\n",
    "    if rot == 'Ry':\n",
    "        return qml.BasicEntanglerLayers.shape(n_layers=n_layers, n_wires=n_wires)\n",
    "    elif rot == 'Rxyz':\n",
    "        return qml.StronglyEntanglingLayers.shape(n_layers=n_layers, n_wires=n_wires)\n",
    "\n",
    "def entangler(weights, wires, rot='Rxyz'):\n",
    "    \"\"\"Apply entangling layers\"\"\"\n",
    "    if rot == 'Ry':\n",
    "        qml.BasicEntanglerLayers(weights, wires=wires, rotation=qml.RY)\n",
    "    elif rot == 'Rxyz':\n",
    "        qml.StronglyEntanglingLayers(weights, wires=wires)\n",
    "\n",
    "def swap(from_wires, to_wires):\n",
    "    \"\"\"Apply SWAP gates\"\"\"\n",
    "    for i in range(len(from_wires)):\n",
    "        qml.SWAP(wires=[from_wires[i], to_wires[i]])\n",
    "\n",
    "def swap_test(from_wires, to_wires, ancila_wire):\n",
    "    \"\"\"Apply SWAP test\"\"\"\n",
    "    qml.Hadamard(wires=ancila_wire)\n",
    "    for i in range(len(from_wires)):\n",
    "        qml.CSWAP(wires=[ancila_wire, from_wires[i], to_wires[i]])\n",
    "    qml.Hadamard(wires=ancila_wire)\n",
    "\n",
    "# Stage 1: Inverted Decoder Model (same as Sidekick)\n",
    "def qae_inv_decoder_model_shape(n_latent, n_trash, n_layers=1, rot='Rxyz'):\n",
    "    return entangler_shape(n_layers, n_latent+n_trash, rot=rot)\n",
    "\n",
    "def qae_inv_decoder_model(wires, n_latent, n_trash, n_layers=1, rot='Rxyz'):\n",
    "    n_zero = n_trash\n",
    "    latent_wires = wires[0:n_latent]\n",
    "    trash_wires = wires[n_latent:n_latent+n_trash]\n",
    "    zero_wires = wires[n_latent+n_trash:n_latent+n_trash+n_zero]\n",
    "    data_wires = latent_wires + trash_wires\n",
    "    anz_wires = latent_wires + trash_wires\n",
    "    ancila_wire = wires[-1]\n",
    "\n",
    "    def _qae_inv_decoder(weights, inputs):\n",
    "        sequence_encoder(data_wires, inputs)\n",
    "        qml.Barrier(wires)\n",
    "        entangler(weights, anz_wires, rot=rot)\n",
    "        qml.Barrier(wires)\n",
    "        swap_test(trash_wires, zero_wires, ancila_wire)\n",
    "        qml.Barrier(wires)\n",
    "        return qml.expval(qml.PauliZ(ancila_wire))\n",
    "\n",
    "    return _qae_inv_decoder\n",
    "\n",
    "# Stage 2: Stacked Model (Encoder → Decoder in serial)\n",
    "def qae_stacked_model_shape(n_latent, n_trash, n_layers=1, rot='Rxyz'):\n",
    "    return entangler_shape(n_layers, n_latent+n_trash, rot=rot)\n",
    "\n",
    "def qae_stacked_model(wires, dec_weights, n_latent, n_trash, n_layers=1, rot='Rxyz'):\n",
    "    n_zero = n_trash\n",
    "    latent_wires = wires[0:n_latent]\n",
    "    trash_wires = wires[n_latent:n_latent+n_trash]\n",
    "    zero_wires = wires[n_latent+n_trash:n_latent+n_trash+n_zero]\n",
    "    data_wires = latent_wires + trash_wires\n",
    "\n",
    "    def _qae_stacked(weights, inputs):\n",
    "        # Encoder\n",
    "        sequence_encoder(data_wires, inputs)\n",
    "        entangler(weights, data_wires, rot=rot)\n",
    "        \n",
    "        # Trash SWAP\n",
    "        qml.Barrier(wires)\n",
    "        swap(trash_wires, zero_wires)\n",
    "        qml.Barrier(wires)\n",
    "        \n",
    "        # Decoder (inverted entangler)\n",
    "        qml.adjoint(entangler)(dec_weights, data_wires, rot=rot)\n",
    "        \n",
    "        # Measure all data qubits\n",
    "        return [qml.expval(qml.PauliZ(m)) for m in data_wires]\n",
    "\n",
    "    return _qae_stacked\n",
    "\n",
    "# Stage 3: Full QAE Model (same as Stacked Stage 2, but both weights fixed)\n",
    "def qae_full_model(wires, enc_weights, dec_weights, n_latent, n_trash, n_layers, rot):\n",
    "    n_zero = n_trash\n",
    "    latent_wires = wires[0:n_latent]\n",
    "    trash_wires = wires[n_latent:n_latent+n_trash]\n",
    "    zero_wires = wires[n_latent+n_trash:n_latent+n_trash+n_zero]\n",
    "    data_wires = latent_wires + trash_wires\n",
    "\n",
    "    def _qae_full(inputs):\n",
    "        # Encoder\n",
    "        sequence_encoder(data_wires, inputs)\n",
    "        entangler(enc_weights, data_wires, rot=rot)\n",
    "        \n",
    "        # Trash SWAP\n",
    "        qml.Barrier(wires)\n",
    "        swap(trash_wires, zero_wires)\n",
    "        qml.Barrier(wires)\n",
    "        \n",
    "        # Decoder\n",
    "        qml.adjoint(entangler)(dec_weights, data_wires, rot=rot)\n",
    "        \n",
    "        return [qml.expval(qml.PauliZ(m)) for m in data_wires]\n",
    "\n",
    "    return _qae_full\n",
    "\n",
    "shape_s1 = qae_inv_decoder_model_shape(n_latent, n_trash, n_layers=1, rot=rot)\n",
    "shape_s2 = qae_stacked_model_shape(n_latent, n_trash, n_layers=1, rot=rot)\n",
    "print(f'Stage 1 (Inv Decoder) shape: {shape_s1}')\n",
    "print(f'Stage 2 (Stacked Encoder) shape: {shape_s2}')\n",
    "print(f'Architecture: {arch_tag()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d1d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 4 — Cost Functions & Training Utilities\n",
    "# ===========================\n",
    "\n",
    "# SWAP test cost (for Stage 1)\n",
    "def cost_probs_on_ancila(expvals):\n",
    "    \"\"\"SWAP test cost function: 1 - P(|1>)\"\"\"\n",
    "    cost = 0\n",
    "    vals = len(expvals)\n",
    "    for i in range(vals):\n",
    "        p1 = (1 - expvals[i]) / 2\n",
    "        cost = cost + p1\n",
    "    return cost / vals\n",
    "\n",
    "def cost_fun_gen_on_probs(model, cost_fun):\n",
    "    \"\"\"Generate cost function for SWAP test model\"\"\"\n",
    "    def _cost_fun(params, inputs):\n",
    "        expvals = pnp.stack([model(params, x) for x in inputs])\n",
    "        return cost_fun(expvals)\n",
    "    return _cost_fun\n",
    "\n",
    "# MSE cost (for Stage 2 - Stacked)\n",
    "def mse_cost_on_tensors(targets, predictions):\n",
    "    \"\"\"Pure MSE cost for expectation values\"\"\"\n",
    "    cost = 0\n",
    "    vals = 0\n",
    "    for i in range(len(targets)):\n",
    "        for w in range(len(targets[i])):\n",
    "            cost = cost + (targets[i][w] - predictions[i][w]) ** 2\n",
    "            vals += 1\n",
    "    return cost / vals\n",
    "\n",
    "def cost_fun_gen_on_tensors(model, cost_fun):\n",
    "    \"\"\"Generate cost function for MSE on tensors\"\"\"\n",
    "    def _cost_fun(params, inputs, targets):\n",
    "        preds = [model(params, x) for x in inputs]\n",
    "        return cost_fun(targets, preds)\n",
    "    return _cost_fun\n",
    "\n",
    "def get_mini_batches(W_noisy, W_clean, batch_size=10, shuffle=True, seed=0):\n",
    "    \"\"\"Generate mini-batches for training\"\"\"\n",
    "    if seed == 0:\n",
    "        seed = int(time.time()*1000) % 10000\n",
    "    np.random.seed(seed)\n",
    "    num_samples = W_clean.shape[0]\n",
    "    indices = np.arange(num_samples)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "    \n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_indices = indices[i:i + batch_size]\n",
    "        yield W_noisy[batch_indices], W_clean[batch_indices]\n",
    "\n",
    "def create_sw_tens(X, y, noise=0.0, wind_size=5, wind_step=2, \n",
    "                   range_low=0.2, range_high=0.8, seed=0, noise_clip=True):\n",
    "    \"\"\"Create sliding window tensors with optional noise\"\"\"\n",
    "    y_noisy = ts_add_noise(y, noise=noise, noise_type='normal', clip=noise_clip,\n",
    "                          range_low=range_low, range_high=range_high, seed=seed)\n",
    "    y_ts = ts_wind_make(y_noisy, wind_size, wind_step)\n",
    "    X_ts = ts_wind_make(X, wind_size, wind_step)\n",
    "    X_train_ts, y_train_ts, X_test_ts, y_test_ts = ts_wind_split(X_ts, y_ts, split)\n",
    "    \n",
    "    X_train_tens = pnp.array(X_train_ts, requires_grad=False)\n",
    "    y_train_tens = pnp.array(y_train_ts, requires_grad=False)\n",
    "    X_test_tens = pnp.array(X_test_ts, requires_grad=False)\n",
    "    y_test_tens = pnp.array(y_test_ts, requires_grad=False)\n",
    "    return X_train_tens, y_train_tens, X_test_tens, y_test_tens\n",
    "\n",
    "# Stage 1: Inverted Decoder Training (same as Sidekick)\n",
    "def train_inv_decoder(model, X, cost_fun, optimizer, n_epochs, init_weights,\n",
    "                      log_interv=1, prompt_fract=0.1, start_time=0, seed=0,\n",
    "                      wind_size=8, wind_step=4, enc_lim=(0, 1)):\n",
    "    \"\"\"Train inverted decoder without noise\"\"\"\n",
    "    scale_low, scale_high = enc_lim\n",
    "    \n",
    "    if seed == 0:\n",
    "        seed = int(time.time()*1000) % 10000\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    hist_cost = []\n",
    "    hist_params = []\n",
    "    params = init_weights.copy()\n",
    "    \n",
    "    _, y_pure_tens, _, _ = create_sw_tens(X, X, noise=0, seed=seed,\n",
    "        wind_size=wind_size, wind_step=wind_step, range_low=scale_low, \n",
    "        range_high=scale_high, noise_clip=noise_clip)\n",
    "    \n",
    "    if start_time == 0:\n",
    "        start_time = time.time()\n",
    "    \n",
    "    for iter in range(n_epochs):\n",
    "        params, cost = optimizer.step_and_cost(lambda p: cost_fun(p, y_pure_tens), params)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        if iter % log_interv == 0:\n",
    "            hist_cost.append(cost)\n",
    "            hist_params.append(params)\n",
    "        \n",
    "        if (prompt_fract > 0) and (iter % int(prompt_fract*n_epochs) == 0):\n",
    "            print(f'Iter: {iter:03d} ({int(elapsed_time):04d} sec) cost={cost:0.6f}')\n",
    "    \n",
    "    min_cost = np.min(hist_cost)\n",
    "    min_iter = np.argmin(hist_cost)\n",
    "    elapsed = int(time.time() - start_time)\n",
    "    print(f'\\nStage 1 completed: epochs={n_epochs}, min cost={min_cost:.6f} @ {min_iter}, ' +\n",
    "          f'time={elapsed} sec\\n')\n",
    "    \n",
    "    return hist_cost, hist_params, init_weights, (min_iter, min_cost, elapsed)\n",
    "\n",
    "# Stage 2: Stacked Training (MSE cost on expectation values)\n",
    "def train_stacked_with_noise(model, W, cost_fun, optimizer, n_epochs, init_weights,\n",
    "                              log_interv=1, prompt_fract=0.1, start_time=0, seed=0,\n",
    "                              wind_size=8, wind_step=4, noise=0,\n",
    "                              enc_lim=(0, 1), dec_lim=(0, 1)):\n",
    "    \"\"\"Train stacked encoder with noisy mini-batches using MSE cost\"\"\"\n",
    "    enc_low, enc_high = enc_lim\n",
    "    dec_low, dec_high = dec_lim\n",
    "    \n",
    "    if seed == 0:\n",
    "        seed = int(time.time()*1000) % 10000\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    hist_cost = []\n",
    "    hist_params = []\n",
    "    params = init_weights.copy()\n",
    "    \n",
    "    # Prepare pure windows as TARGETS (scaled to dec range)\n",
    "    _, y_pure_tens, _, _ = create_sw_tens(W, W, noise=0, seed=seed,\n",
    "        wind_size=wind_size, wind_step=wind_step, range_low=enc_low, \n",
    "        range_high=enc_high, noise_clip=noise_clip)\n",
    "    \n",
    "    # Scale targets to expectation value range [-1, 1]\n",
    "    y_pure_tens = x2y(y_pure_tens, xlim=(enc_low, enc_high), ylim=(dec_low, dec_high))\n",
    "    \n",
    "    if start_time == 0:\n",
    "        start_time = time.time()\n",
    "    \n",
    "    for iter in range(n_epochs):\n",
    "        # Generate noisy windows as INPUTS\n",
    "        _, X_noisy_tens, _, _ = create_sw_tens(W, W, noise=noise, seed=seed+iter,\n",
    "            wind_size=wind_size, wind_step=wind_step, range_low=enc_low, \n",
    "            range_high=enc_high, noise_clip=noise_clip)\n",
    "        \n",
    "        # Decay learning rate\n",
    "        if (iter+1) % lr_stacked_decay_steps == 0:\n",
    "            optimizer.stepsize *= lr_stacked_decay_rate\n",
    "        \n",
    "        # Train in mini-batches\n",
    "        batches = get_mini_batches(X_noisy_tens, y_pure_tens, batch_size=batch_size,\n",
    "                                   shuffle=True, seed=seed+iter)\n",
    "        acc_batch_cost = 0\n",
    "        for batch_no, (noisy_batch, pure_batch) in enumerate(batches):\n",
    "            params, batch_cost = optimizer.step_and_cost(\n",
    "                lambda p: cost_fun(p, noisy_batch, pure_batch), params)\n",
    "            acc_batch_cost += batch_cost\n",
    "        \n",
    "        cost = acc_batch_cost / (batch_no + 1)\n",
    "        \n",
    "        if iter % log_interv == 0:\n",
    "            hist_cost.append(cost)\n",
    "            hist_params.append(params)\n",
    "        \n",
    "        if (prompt_fract > 0) and (iter % int(prompt_fract*n_epochs) == 0):\n",
    "            elapsed = int(time.time() - start_time)\n",
    "            print(f'Iter: {iter:03d} ({elapsed:04d} sec) cost={cost:0.6f}, ' +\n",
    "                  f'min={np.min(hist_cost):0.6f} (LR={optimizer.stepsize:0.4f})')\n",
    "    \n",
    "    min_cost = np.min(hist_cost)\n",
    "    min_iter = np.argmin(hist_cost)\n",
    "    elapsed = int(time.time() - start_time)\n",
    "    print(f'\\nStage 2 completed: epochs={n_epochs}, min cost={min_cost:.6f} @ {min_iter}, ' +\n",
    "          f'time={elapsed} sec\\n')\n",
    "    \n",
    "    return hist_cost, hist_params, init_weights, (min_iter, min_cost, elapsed)\n",
    "\n",
    "# Evaluation helpers\n",
    "def _flatten_avg(windows):\n",
    "    \"\"\"Flatten overlapping windows by averaging\"\"\"\n",
    "    return ts_wind_flatten_avg(np.asarray(windows), wind_step)\n",
    "\n",
    "def _mse(a, b):\n",
    "    \"\"\"Calculate MSE between two sequences\"\"\"\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "    return float(np.mean((a - b) ** 2))\n",
    "\n",
    "def windows_from_seed(y_vec, sigma, seed, clip=True):\n",
    "    \"\"\"Generate clean and noisy windows with fixed seed\"\"\"\n",
    "    y_noisy = ts_add_noise(y_vec, noise=sigma, noise_type='normal', clip=clip,\n",
    "                          range_low=scale_low, range_high=scale_high, seed=seed)\n",
    "    win_clean = ts_wind_make(y_vec, wind_size, wind_step)\n",
    "    win_noisy = ts_wind_make(y_noisy, wind_size, wind_step)\n",
    "    X_ts = np.array([i*wind_step for i in range(len(win_clean))])\n",
    "    _, tr_clean, _, te_clean = ts_wind_split(X_ts, win_clean, split)\n",
    "    _, tr_noisy, _, te_noisy = ts_wind_split(X_ts, win_noisy, split)\n",
    "    return tr_clean, tr_noisy, te_clean, te_noisy\n",
    "\n",
    "def run_qnode_series(model, windows):\n",
    "    \"\"\"Run model on series of windows (no params for full QAE)\"\"\"\n",
    "    outs = []\n",
    "    for w in windows:\n",
    "        z = model(w)\n",
    "        outs.append(np.asarray(z))\n",
    "    return np.stack(outs)\n",
    "\n",
    "def render_circuit_stage1(L, weights_vec, save_dir, inst, seed=None):\n",
    "    \"\"\"Render Stage 1 (inverted decoder) circuit\"\"\"\n",
    "    wires = list(range(n_latent + 2*n_trash + 1))\n",
    "    qae = qae_inv_decoder_model(wires, n_latent, n_trash, n_layers=L, rot=rot)\n",
    "    \n",
    "    if seed is not None:\n",
    "        dev = qml.device(sim, wires=len(wires), shots=shots, seed=seed)\n",
    "    else:\n",
    "        dev = qml.device(sim, wires=len(wires), shots=shots)\n",
    "    \n",
    "    qnode = qml.QNode(qae, dev)\n",
    "    \n",
    "    x_dummy = np.zeros(wind_size, dtype=float)\n",
    "    qml.drawer.use_style(\"pennylane\")\n",
    "    fig_func = qml.draw_mpl(qnode, decimals=2, level=\"device\")\n",
    "    fig, ax = fig_func(weights_vec, x_dummy)\n",
    "    ax.set_title(f'Stacked Stage 1: Inv Decoder (L={L}, inst={inst})')\n",
    "    \n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_eps = save_dir / f\"circuit_stage1_{arch_tag()}_L{L}_inst{inst:02d}.eps\"\n",
    "    fig.savefig(out_eps, dpi=220, bbox_inches=\"tight\", pad_inches=0.1, format=\"eps\")\n",
    "    plt.close(fig)\n",
    "    return out_eps\n",
    "\n",
    "def render_circuit_stage2(L, dec_weights, enc_weights, save_dir, inst, seed=None):  # ✅ ADDED seed param\n",
    "    \"\"\"Render Stage 2 (stacked) circuit\"\"\"\n",
    "    wires = list(range(n_latent + 2*n_trash))\n",
    "    qae = qae_stacked_model(wires, dec_weights, n_latent, n_trash, n_layers=L, rot=rot)\n",
    "    \n",
    "    if seed is not None:\n",
    "        dev = qml.device(sim, wires=len(wires), shots=shots, seed=seed)\n",
    "    else:\n",
    "        dev = qml.device(sim, wires=len(wires), shots=shots)\n",
    "    \n",
    "    qnode = qml.QNode(qae, dev)\n",
    "    \n",
    "    x_dummy = np.zeros(wind_size, dtype=float)\n",
    "    qml.drawer.use_style(\"pennylane\")\n",
    "    fig_func = qml.draw_mpl(qnode, decimals=2, level=\"device\")\n",
    "    fig, ax = fig_func(enc_weights, x_dummy)\n",
    "    ax.set_title(f'Stacked Stage 2: Full Stacked (L={L}, inst={inst})')\n",
    "    \n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_eps = save_dir / f\"circuit_stage2_{arch_tag()}_L{L}_inst{inst:02d}.eps\"\n",
    "    fig.savefig(out_eps, dpi=220, bbox_inches=\"tight\", pad_inches=0.1, format=\"eps\")\n",
    "    plt.close(fig)\n",
    "    return out_eps\n",
    "\n",
    "def render_circuit_full(L, enc_weights, dec_weights, save_dir, inst, seed=None):  # ✅ ADDED seed param\n",
    "    \"\"\"Render full QAE circuit\"\"\"\n",
    "    wires = list(range(n_wires_full))\n",
    "    qae = qae_full_model(wires, enc_weights, dec_weights, n_latent, n_trash, L, rot)\n",
    "    \n",
    "    if seed is not None:\n",
    "        dev = qml.device(sim, wires=n_wires_full, shots=shots, seed=seed)\n",
    "    else:\n",
    "        dev = qml.device(sim, wires=n_wires_full, shots=shots)\n",
    "    \n",
    "    qnode = qml.QNode(qae, dev)\n",
    "    \n",
    "    x_dummy = np.zeros(wind_size, dtype=float)\n",
    "    qml.drawer.use_style(\"pennylane\")\n",
    "    fig_func = qml.draw_mpl(qnode, decimals=2, level=\"device\")\n",
    "    fig, ax = fig_func(x_dummy)\n",
    "    ax.set_title(f'Stacked Full QAE (L={L}, inst={inst})')\n",
    "    \n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_eps = save_dir / f\"circuit_full_{arch_tag()}_L{L}_inst{inst:02d}.eps\"\n",
    "    fig.savefig(out_eps, dpi=220, bbox_inches=\"tight\", pad_inches=0.1, format=\"eps\")\n",
    "    plt.close(fig)\n",
    "    return out_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda10172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 5 — Multi-Instance Training\n",
    "# ===========================\n",
    "import pandas as pd\n",
    "\n",
    "def ensure_dir(p):\n",
    "    \"\"\"Create directory if it doesn't exist\"\"\"\n",
    "    p = Path(p)\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "# Setup directory structure\n",
    "ROOT = ensure_dir(BUNDLE_ROOT)\n",
    "DATA_ROOT = ensure_dir(ROOT / DATA_ID)\n",
    "ARCH_ROOT = ensure_dir(DATA_ROOT / arch_tag())\n",
    "CSV_RUNS = ARCH_ROOT / \"metrics_by_run.csv\"\n",
    "CSV_SUMMARY = ARCH_ROOT / \"summary_by_layer.csv\"\n",
    "\n",
    "RUNS_HEADER = [\n",
    "    \"dataset\", \"arch\", \"instance_id\", \"layer\",\n",
    "    \"window_size\", \"step\", \"sigma_eval\",\n",
    "    \"stage1_min_cost\", \"stage1_time_sec\",\n",
    "    \"stage2_min_cost\", \"stage2_time_sec\",\n",
    "    \"mse_train_noise\", \"mse_train_recovered\", \"delta_train_pct\",\n",
    "    \"mse_test_noise\", \"mse_test_recovered\", \"delta_test_pct\",\n",
    "    \"mse_train_recovered_pure\", \"mse_test_recovered_pure\",\n",
    "    \"timestamp\", \"bundle_json\"\n",
    "]\n",
    "\n",
    "if not CSV_RUNS.exists():\n",
    "    with open(CSV_RUNS, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        csv.writer(f).writerow(RUNS_HEADER)\n",
    "\n",
    "ALL_RUNS = []\n",
    "\n",
    "# Encode data once\n",
    "y_enc = x2y(y, xlim=(scale_low, scale_high), ylim=(y_enc_low, y_enc_high))\n",
    "\n",
    "for L in LAYER_OPTIONS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING LAYER {L}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Get shapes\n",
    "    shape_s1 = qae_inv_decoder_model_shape(n_latent, n_trash, n_layers=L, rot=rot)\n",
    "    shape_s2 = qae_stacked_model_shape(n_latent, n_trash, n_layers=L, rot=rot)\n",
    "    \n",
    "    layer_dir = ensure_dir(ARCH_ROOT / f\"L{L}\")\n",
    "    \n",
    "    for inst in INSTANCES_PER_LAYER:\n",
    "        print(f\"\\n{'─'*60}\")\n",
    "        print(f\"Layer {L} | Instance {inst}\")\n",
    "        print(f\"{'─'*60}\")\n",
    "        \n",
    "        \n",
    "        seed_info = set_global_seed(inst, layer=L)\n",
    "        device_seed = seed_info['device_seed']\n",
    "        print(f\"Seeds: global={seed_info['global_seed']}, device={device_seed}\")\n",
    "        \n",
    "        # ============================================================\n",
    "        # STAGE 1: Train Inverted Decoder\n",
    "        # ============================================================\n",
    "        print(f\"\\n▶ STAGE 1: Training Inverted Decoder\")\n",
    "        \n",
    "        wires_s1 = list(range(n_latent + 2*n_trash + 1))\n",
    "        dev_s1 = qml.device(sim, wires=len(wires_s1), shots=shots, seed=device_seed)\n",
    "        qae_inv_dec = qae_inv_decoder_model(wires_s1, n_latent, n_trash, n_layers=L, rot=rot)\n",
    "        qae_inv_dec_qc = qml.QNode(qae_inv_dec, dev_s1, interface=interface, diff_method=diff_method)\n",
    "        \n",
    "        init_weights_s1 = pnp.array(\n",
    "            np.random.uniform(high=2*np.pi, size=shape_s1) * inv_decoder_weight_scaler,\n",
    "            requires_grad=True)\n",
    "        \n",
    "        opt_s1 = qml.AdamOptimizer(stepsize=lr_inv_decoder_initial)\n",
    "        cost_fun_s1 = cost_fun_gen_on_probs(qae_inv_dec_qc, cost_probs_on_ancila)\n",
    "        \n",
    "        hist_cost_s1, hist_params_s1, _, stats_s1 = train_inv_decoder(\n",
    "            qae_inv_dec_qc, y_enc, cost_fun_s1, opt_s1, n_inv_decoder_epochs,\n",
    "            init_weights_s1, log_interv=log_interv, prompt_fract=0.1,\n",
    "            seed=TRAIN_SEED_BASE, wind_size=wind_size, wind_step=wind_step,\n",
    "            enc_lim=(y_enc_low, y_enc_high))\n",
    "        \n",
    "        min_iter_s1, min_cost_s1, elapsed_s1 = stats_s1\n",
    "        opt_weights_s1 = hist_params_s1[min_iter_s1]\n",
    "        \n",
    "        # ============================================================\n",
    "        # STAGE 2: Train Stacked Encoder\n",
    "        # ============================================================\n",
    "        print(f\"\\n▶ STAGE 2: Training Stacked Encoder\")\n",
    "        \n",
    "        wires_s2 = list(range(n_latent + 2*n_trash))\n",
    "        dev_s2 = qml.device(sim, wires=len(wires_s2), shots=shots, seed=device_seed)\n",
    "        qae_stacked = qae_stacked_model(wires_s2, opt_weights_s1, n_latent, n_trash, n_layers=L, rot=rot)\n",
    "        qae_stacked_qc = qml.QNode(qae_stacked, dev_s2, interface=interface, diff_method=diff_method)\n",
    "        \n",
    "        # Initialize encoder with decoder weights (mirror strategy)\n",
    "        init_weights_s2 = opt_weights_s1.copy()\n",
    "        \n",
    "        opt_s2 = qml.AdamOptimizer(stepsize=lr_stacked_initial, beta1=0.99)\n",
    "        cost_fun_s2 = cost_fun_gen_on_tensors(qae_stacked_qc, mse_cost_on_tensors)\n",
    "        \n",
    "        hist_cost_s2, hist_params_s2, _, stats_s2 = train_stacked_with_noise(\n",
    "            qae_stacked_qc, y_enc, cost_fun_s2, opt_s2, n_stacked_epochs,\n",
    "            init_weights_s2, log_interv=log_interv, prompt_fract=0.1,\n",
    "            seed=TRAIN_SEED_BASE, wind_size=wind_size, wind_step=wind_step,\n",
    "            noise=noise, enc_lim=(y_enc_low, y_enc_high), dec_lim=(y_dec_low, y_dec_high))\n",
    "        \n",
    "        min_iter_s2, min_cost_s2, elapsed_s2 = stats_s2\n",
    "        opt_weights_s2 = hist_params_s2[min_iter_s2]\n",
    "        \n",
    "        # ============================================================\n",
    "        # STAGE 3: Evaluate Full QAE\n",
    "        # ============================================================\n",
    "        print(f\"\\n▶ STAGE 3: Evaluating Full QAE\")\n",
    "        \n",
    "        wires_full = list(range(n_wires_full))\n",
    "        dev_full = qml.device(sim, wires=n_wires_full, shots=shots, seed=device_seed)\n",
    "        qae_full = qae_full_model(wires_full, opt_weights_s2, opt_weights_s1, n_latent, n_trash, L, rot)\n",
    "        qae_full_qc = qml.QNode(qae_full, dev_full, interface=interface, diff_method=diff_method)\n",
    "        \n",
    "        # Generate test data with fixed seed\n",
    "        tr_c, tr_n, te_c, te_n = windows_from_seed(y, noise, TEST_SEED_FIXED, clip=True)\n",
    "        tr_n_enc = x2y(tr_n, xlim=(scale_low, scale_high), ylim=(y_enc_low, y_enc_high))\n",
    "        te_n_enc = x2y(te_n, xlim=(scale_low, scale_high), ylim=(y_enc_low, y_enc_high))\n",
    "        \n",
    "        tr_c_enc = x2y(tr_c, xlim=(scale_low, scale_high), ylim=(y_enc_low, y_enc_high))\n",
    "        te_c_enc = x2y(te_c, xlim=(scale_low, scale_high), ylim=(y_enc_low, y_enc_high))\n",
    "        \n",
    "        # Run inference\n",
    "        tr_hat = run_qnode_series(qae_full_qc, tr_n_enc)\n",
    "        te_hat = run_qnode_series(qae_full_qc, te_n_enc)\n",
    "        tr_hat_pure = run_qnode_series(qae_full_qc, tr_c_enc)\n",
    "        te_hat_pure = run_qnode_series(qae_full_qc, te_c_enc)\n",
    "        \n",
    "        # Flatten and rescale\n",
    "        tr_pure = _flatten_avg(tr_c)\n",
    "        te_pure = _flatten_avg(te_c)\n",
    "        tr_noi = _flatten_avg(tr_n)\n",
    "        te_noi = _flatten_avg(te_n)\n",
    "        tr_rec = x2y(_flatten_avg(tr_hat), xlim=(y_dec_low, y_dec_high), ylim=(scale_low, scale_high))\n",
    "        te_rec = x2y(_flatten_avg(te_hat), xlim=(y_dec_low, y_dec_high), ylim=(scale_low, scale_high))\n",
    "        tr_rec_pure = x2y(_flatten_avg(tr_hat_pure), xlim=(y_dec_low, y_dec_high), ylim=(scale_low, scale_high))\n",
    "        te_rec_pure = x2y(_flatten_avg(te_hat_pure), xlim=(y_dec_low, y_dec_high), ylim=(scale_low, scale_high))\n",
    "        \n",
    "        # Compute metrics\n",
    "        mse_tr_noise = _mse(tr_pure, tr_noi)\n",
    "        mse_te_noise = _mse(te_pure, te_noi)\n",
    "        mse_tr_rec = _mse(tr_pure, tr_rec)\n",
    "        mse_te_rec = _mse(te_pure, te_rec)\n",
    "        mse_tr_rec_pure = _mse(tr_pure, tr_rec_pure)\n",
    "        mse_te_rec_pure = _mse(te_pure, te_rec_pure)\n",
    "        \n",
    "        delta_tr = 100.0 * (1.0 - mse_tr_rec / max(mse_tr_noise, 1e-12))\n",
    "        delta_te = 100.0 * (1.0 - mse_te_rec / max(mse_te_noise, 1e-12))\n",
    "        \n",
    "        print(f\"Test MSE: noise={mse_te_noise:.6f}, recovered={mse_te_rec:.6f}, Δ={delta_te:+.2f}%\")\n",
    "        \n",
    "        # Save artifacts\n",
    "        inst_tag = f\"inst{inst:02d}_L{L}\"\n",
    "        \n",
    "        np.save(layer_dir / f\"weights_s1_{inst_tag}.npy\", np.array(opt_weights_s1))\n",
    "        np.save(layer_dir / f\"weights_s2_{inst_tag}.npy\", np.array(opt_weights_s2))\n",
    "        \n",
    "        circuit_s1_path = render_circuit_stage1(L, np.array(opt_weights_s1), ARCH_ROOT, inst, seed=device_seed)\n",
    "        circuit_s2_path = render_circuit_stage2(L, np.array(opt_weights_s1), np.array(opt_weights_s2), ARCH_ROOT, inst, seed=device_seed)\n",
    "        circuit_full_path = render_circuit_full(L, np.array(opt_weights_s2), np.array(opt_weights_s1), ARCH_ROOT, inst, seed=device_seed)\n",
    "        \n",
    "        # Save training costs\n",
    "        cost_s1_plot = layer_dir / f\"training_cost_s1_{inst_tag}.eps\"\n",
    "        meas_plot(hist_cost_s1, meas='cost', task='min',\n",
    "                  title_pref=f'L{L} Inst {inst} Stage 1 Training',\n",
    "                  ylim=(0, max(0.15, max(hist_cost_s1)*1.1)), rcParams=(10, 4),\n",
    "                  log_interv=log_interv, backplot=True, back_color='lightgray',\n",
    "                  smooth_weight=0.5, save_plot=cost_s1_plot)\n",
    "        \n",
    "        cost_s2_plot = layer_dir / f\"training_cost_s2_{inst_tag}.eps\"\n",
    "        meas_plot(hist_cost_s2, meas='cost', task='min',\n",
    "                  title_pref=f'L{L} Inst {inst} Stage 2 Training',\n",
    "                  ylim=(0, max(0.15, max(hist_cost_s2)*1.1)), rcParams=(10, 4),\n",
    "                  log_interv=log_interv, backplot=True, back_color='lightgray',\n",
    "                  smooth_weight=0.9, save_plot=cost_s2_plot)\n",
    "        \n",
    "        # Save cost histories\n",
    "        with open(layer_dir / f\"cost_s1_{inst_tag}.json\", \"w\") as f:\n",
    "            json.dump([float(c) for c in hist_cost_s1], f, indent=2)\n",
    "        with open(layer_dir / f\"cost_s2_{inst_tag}.json\", \"w\") as f:\n",
    "            json.dump([float(c) for c in hist_cost_s2], f, indent=2)\n",
    "        \n",
    "        # Create coordinate arrays\n",
    "        n_train = len(tr_pure)\n",
    "        n_test = len(te_pure)\n",
    "        X_coords_train = np.arange(0, n_train * wind_step, wind_step)[:n_train]\n",
    "        X_coords_test = np.arange(n_train * wind_step,\n",
    "                                  n_train * wind_step + n_test * wind_step,\n",
    "                                  wind_step)[:n_test]\n",
    "        \n",
    "        # Plot reconstruction from pure data\n",
    "        recon_pure_path = layer_dir / f\"reconstruction_pure_{inst_tag}.eps\"\n",
    "        multi_plot_flat_ts(\n",
    "            X_list=[X_coords_train, X_coords_test, X_coords_train, X_coords_test, X_coords_train, X_coords_test],\n",
    "            y_list=[tr_noi, te_noi, tr_pure, te_pure, tr_rec_pure, te_rec_pure],\n",
    "            labels=[f\"Noisy train (MSE {mse_tr_noise:0.4f})\",\n",
    "                    f\"Noisy test  (MSE {mse_te_noise:0.4f})\",\n",
    "                    \"True train\", \"True test\",\n",
    "                    f\"Recovered train (MSE {mse_tr_rec_pure:0.4f})\",\n",
    "                    f\"Recovered test  (MSE {mse_te_rec_pure:0.4f})\"],\n",
    "            vert_lines=['', 'dotted', '', '', '', ''], \n",
    "            vert_line_color='gray',\n",
    "            colors=['lightblue', 'pink', 'cornflowerblue', 'salmon', 'blue', 'red'],\n",
    "            marker_colors=['white', 'white', 'lightblue', 'mistyrose', 'blue', 'red'],\n",
    "            lines=['', '', 'solid', 'solid', 'dashed', 'dashed'],\n",
    "            markers=['.', '.', '', '', '', ''],\n",
    "            rcParams=(12, 6), dpi=200,\n",
    "            xlabel=f'Time (windows: size={wind_size}, step={wind_step})', \n",
    "            ylabel='y Value',\n",
    "            legend_cols=3, \n",
    "            title=f\"Pure data vs recovered from pure data (L={L}, inst={inst})\",\n",
    "            save_plot=recon_pure_path)\n",
    "        \n",
    "        # Plot reconstruction from noisy data\n",
    "        recon_noisy_path = layer_dir / f\"reconstruction_noisy_{inst_tag}.eps\"\n",
    "        multi_plot_flat_ts(\n",
    "            X_list=[X_coords_train, X_coords_test, X_coords_train, X_coords_test, X_coords_train, X_coords_test],\n",
    "            y_list=[tr_noi, te_noi, tr_pure, te_pure, tr_rec, te_rec],\n",
    "            labels=[f\"Noisy train (MSE {mse_tr_noise:0.4f})\",\n",
    "                    f\"Noisy test  (MSE {mse_te_noise:0.4f})\",\n",
    "                    \"True train\", \"True test\",\n",
    "                    f\"Recovered train (MSE {mse_tr_rec:0.4f})\",\n",
    "                    f\"Recovered test  (MSE {mse_te_rec:0.4f})\"],\n",
    "            vert_lines=['', 'dotted', '', '', '', ''], \n",
    "            vert_line_color='gray',\n",
    "            colors=['lightblue', 'pink', 'cornflowerblue', 'salmon', 'blue', 'red'],\n",
    "            marker_colors=['white', 'white', 'lightblue', 'mistyrose', 'blue', 'red'],\n",
    "            lines=['', '', 'solid', 'solid', 'dashed', 'dashed'],\n",
    "            markers=['.', '.', '', '', '', ''],\n",
    "            rcParams=(12, 6), dpi=200,\n",
    "            xlabel=f'Time (windows: size={wind_size}, step={wind_step})', \n",
    "            ylabel='y Value',\n",
    "            legend_cols=3, \n",
    "            title=f\"Pure data vs recovered from noise (L={L}, inst={inst})\",\n",
    "            save_plot=recon_noisy_path)\n",
    "        \n",
    "        # Create bundle\n",
    "        bundle = {\n",
    "            \"schema\": {\"name\": \"stacked_qae_bundle\", \"version\": \"1.0\"},\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"dataset\": {\n",
    "                \"id\": DATA_ID,\n",
    "                \"scale_low\": float(scale_low),\n",
    "                \"scale_high\": float(scale_high),\n",
    "                \"window_size\": int(wind_size),\n",
    "                \"window_step\": int(wind_step),\n",
    "                \"split\": float(split),\n",
    "            },\n",
    "            \"run\": {\n",
    "                \"instance_id\": int(inst),\n",
    "                \"layer\": int(L),\n",
    "                \"sigma_eval\": float(noise),\n",
    "                \"test_seed_fixed\": int(TEST_SEED_FIXED),\n",
    "                \"device_seed\": int(device_seed),\n",
    "                \"stage1_time_sec\": int(elapsed_s1),\n",
    "                \"stage2_time_sec\": int(elapsed_s2),\n",
    "            },\n",
    "            \"environment\": {\n",
    "                \"device\": sim,\n",
    "                \"diff_method\": diff_method,\n",
    "                \"interface\": interface,\n",
    "            },\n",
    "            \"architecture\": {\n",
    "                \"type\": \"stacked\",\n",
    "                \"n_qubits\": int(wind_size),\n",
    "                \"n_latent\": int(n_latent),\n",
    "                \"n_trash\": int(n_trash),\n",
    "                \"rot\": str(rot),\n",
    "            },\n",
    "            \"parameters\": {\n",
    "                \"weights_stage1\": np.array(opt_weights_s1).tolist(),\n",
    "                \"weights_stage2\": np.array(opt_weights_s2).tolist(),\n",
    "            },\n",
    "            \"metrics\": {\n",
    "                \"stage1_min_cost\": float(min_cost_s1),\n",
    "                \"stage2_min_cost\": float(min_cost_s2),\n",
    "                \"mse_train_noise\": float(mse_tr_noise),\n",
    "                \"mse_train_recovered\": float(mse_tr_rec),\n",
    "                \"delta_train_pct\": float(delta_tr),\n",
    "                \"mse_test_noise\": float(mse_te_noise),\n",
    "                \"mse_test_recovered\": float(mse_te_rec),\n",
    "                \"delta_test_pct\": float(delta_te),\n",
    "                \"mse_train_recovered_pure\": float(mse_tr_rec_pure),\n",
    "                \"mse_test_recovered_pure\": float(mse_te_rec_pure),\n",
    "            },\n",
    "            \"artifacts\": {\n",
    "                \"weights_s1_file\": f\"weights_s1_{inst_tag}.npy\",\n",
    "                \"weights_s2_file\": f\"weights_s2_{inst_tag}.npy\",\n",
    "                \"circuit_stage1\": str(circuit_s1_path.name),\n",
    "                \"circuit_stage2\": str(circuit_s2_path.name),\n",
    "                \"circuit_full\": str(circuit_full_path.name),\n",
    "                \"training_cost_s1_plot\": str(cost_s1_plot.name),\n",
    "                \"training_cost_s2_plot\": str(cost_s2_plot.name),\n",
    "                \"reconstruction_pure_plot\": str(recon_pure_path.name),\n",
    "                \"reconstruction_noisy_plot\": str(recon_noisy_path.name),\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        bundle_path = layer_dir / f\"bundle_{inst_tag}.json\"\n",
    "        with open(bundle_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(bundle, f, indent=2)\n",
    "        \n",
    "        # Save to CSV\n",
    "        row = [\n",
    "            DATA_ID, arch_tag(), int(inst), int(L),\n",
    "            int(wind_size), int(wind_step), float(noise),\n",
    "            float(min_cost_s1), int(elapsed_s1),\n",
    "            float(min_cost_s2), int(elapsed_s2),\n",
    "            mse_tr_noise, mse_tr_rec, delta_tr,\n",
    "            mse_te_noise, mse_te_rec, delta_te,\n",
    "            mse_tr_rec_pure, mse_te_rec_pure,\n",
    "            bundle[\"timestamp\"], str(bundle_path)\n",
    "        ]\n",
    "        \n",
    "        if CSV_RUNS.exists():\n",
    "            df_old = pd.read_csv(CSV_RUNS)\n",
    "            df_new = pd.concat([df_old, pd.DataFrame([row], columns=RUNS_HEADER)],\n",
    "                              ignore_index=True)\n",
    "            df_new.to_csv(CSV_RUNS, index=False)\n",
    "        else:\n",
    "            pd.DataFrame([row], columns=RUNS_HEADER).to_csv(CSV_RUNS, index=False)\n",
    "        \n",
    "        ALL_RUNS.append({\n",
    "            \"instance_id\": inst,\n",
    "            \"layer\": L,\n",
    "            \"weights_s1\": np.array(opt_weights_s1),\n",
    "            \"weights_s2\": np.array(opt_weights_s2)\n",
    "        })\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TRAINING COMPLETE\")\n",
    "print(f\"Metrics saved: {CSV_RUNS}\")\n",
    "print(f\"Artifacts saved: {ARCH_ROOT}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Generate summary\n",
    "if CSV_RUNS.exists():\n",
    "    df = pd.read_csv(CSV_RUNS)\n",
    "    summary = (df.groupby(\"layer\", as_index=True)\n",
    "               .agg(runs=(\"instance_id\", \"count\"),\n",
    "                    avg_stage1_time=(\"stage1_time_sec\", \"mean\"),\n",
    "                    avg_stage2_time=(\"stage2_time_sec\", \"mean\"),\n",
    "                    mse_test_noise_mean=(\"mse_test_noise\", \"mean\"),\n",
    "                    mse_test_recovered_mean=(\"mse_test_recovered\", \"mean\"),\n",
    "                    delta_test_pct_mean=(\"delta_test_pct\", \"mean\")))\n",
    "    summary.to_csv(CSV_SUMMARY)\n",
    "    print(f\"\\nSummary saved: {CSV_SUMMARY}\")\n",
    "    print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
